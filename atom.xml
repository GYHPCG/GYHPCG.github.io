<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>A tour of my learing</title>
  
  <subtitle>All in CS</subtitle>
  <link href="https://gyhpcg.gihthub.io/atom.xml" rel="self"/>
  
  <link href="https://gyhpcg.gihthub.io/"/>
  <updated>2023-12-19T15:27:42.152Z</updated>
  <id>https://gyhpcg.gihthub.io/</id>
  
  <author>
    <name>pancg</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Hive数仓</title>
    <link href="https://gyhpcg.gihthub.io/2023/12/19/Hive%E6%95%B0%E4%BB%93/"/>
    <id>https://gyhpcg.gihthub.io/2023/12/19/Hive%E6%95%B0%E4%BB%93/</id>
    <published>2023-12-19T15:14:30.000Z</published>
    <updated>2023-12-19T15:27:42.152Z</updated>
    
    <content type="html"><![CDATA[<h1 id="数据库-OLTP-和数据仓库-OLAP"><a href="#数据库-OLTP-和数据仓库-OLAP" class="headerlink" title="数据库(OLTP)和数据仓库(OLAP)"></a>数据库(OLTP)和数据仓库(OLAP)</h1><table><thead><tr><th>功能</th><th>数据库</th><th>数据仓库</th></tr></thead><tbody><tr><td>数据1</td><td>数据2</td><td>数据3</td></tr><tr><td>数据4</td><td>数据5</td><td>数据6</td></tr></tbody></table>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;数据库-OLTP-和数据仓库-OLAP&quot;&gt;&lt;a href=&quot;#数据库-OLTP-和数据仓库-OLAP&quot; class=&quot;headerlink&quot; title=&quot;数据库(OLTP)和数据仓库(OLAP)&quot;&gt;&lt;/a&gt;数据库(OLTP)和数据仓库(OLAP)&lt;/h1&gt;&lt;ta</summary>
      
    
    
    
    <category term="big Data" scheme="https://gyhpcg.gihthub.io/categories/big-Data/"/>
    
    
    <category term="Hive" scheme="https://gyhpcg.gihthub.io/tags/Hive/"/>
    
  </entry>
  
  <entry>
    <title>大数据原理技术</title>
    <link href="https://gyhpcg.gihthub.io/2023/12/17/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%8E%9F%E7%90%86%E6%8A%80%E6%9C%AF/"/>
    <id>https://gyhpcg.gihthub.io/2023/12/17/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%8E%9F%E7%90%86%E6%8A%80%E6%9C%AF/</id>
    <published>2023-12-17T07:21:27.000Z</published>
    <updated>2023-12-25T07:56:59.843Z</updated>
    
    <content type="html"><![CDATA[<h1 id="大数据原理期末复习"><a href="#大数据原理期末复习" class="headerlink" title="大数据原理期末复习"></a>大数据原理期末复习</h1><h2 id="Hadoop"><a href="#Hadoop" class="headerlink" title="Hadoop"></a>Hadoop</h2><h3 id="Hadoop的特点"><a href="#Hadoop的特点" class="headerlink" title="Hadoop的特点"></a>Hadoop的特点</h3><ol><li>扩容能力(Scalable)：<br>Hadoop是在计算机集群内分配并完成计算任务，集群可以方便的扩展到数以千个节点</li><li>低成本(Economical)：<br> Hadoop通过普通廉价的机器组成服务器集群来分发以及处理数据，以至于成本很低</li><li>高效率(Efficient)：<br>Hadoop可以在节点之间动态并行的移动数据，使得速度非常快</li><li>可靠性(Rellable)：<br>能自动维护数据的多份复制，并且在任务失败后能自动的重新部署计算任务</li></ol><p><img src="/../img/bigData/hadoop1.png" alt="Alt text"></p><h3 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h3><h3 id="HDFS读写流程"><a href="#HDFS读写流程" class="headerlink" title="HDFS读写流程"></a>HDFS读写流程</h3><h4 id="HDFS读-下载-流程"><a href="#HDFS读-下载-流程" class="headerlink" title="HDFS读(下载)流程"></a>HDFS读(下载)流程</h4><p><img src="/../img/bigData/hdfs_read.png" alt="hdfs_read"></p><ol><li>客户端通过Distributed FileSystem项<strong>NN</strong>请求下载文件，NN通过查询元数据，找到文件所在的DN(DataNode)地址</li><li>挑选一台DataNode(就近原则，然后随机)服务器，请求读取数据。</li><li>DN开始传输数据给客户端(从磁盘里面读取数据输入流，以Packet为单位来做校验)</li><li>客户端以Packet为单位接收，先在本地缓存，然后写入目标文件</li></ol><h4 id="HDFS写-上传-流程"><a href="#HDFS写-上传-流程" class="headerlink" title="HDFS写(上传)流程"></a>HDFS写(上传)流程</h4><p><img src="/../img/bigData/hdfs_write.png" alt="hdfs_write"></p><ol><li>客户端通过Distributed FileSystem模块向NN请求上传文件，NN检查目标文件是否已存在，父目录是否存在。</li><li>NN返回是否可以上传</li><li>客户端请求第一个Block上传到哪几个DataNode服务器上。</li><li>NN返回3个DataNode节点，分别为dn1、dn2、dn3</li><li>客户端通过FSDataOutputStream模块请求dn1上传数据，dn1收到请求会继续会调用dn2,然后dn2调用dn3,将这个通信管道建立完成。</li><li>dn1、dn2、dn3逐级应答客户端。</li><li>客户端开始往dn1上传第一个Block(先从磁盘读取数据放到一个本地内存缓存)，以Packet为单位，dn1收到一个Packet就会传给dn2,dn2传给dn3; dn1每传一个packet会放入一个确认队列等待确认。</li><li>当一个Block传输完成之后，客户端再次请求NN上传第二个Block的服务器。(重复执行3-7步)<br> 验证Packet代码 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"> <span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testUploadPacket</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line"><span class="comment">//1 准备读取本地文件的输入流</span></span><br><span class="line"><span class="keyword">final</span> <span class="type">FileInputStream</span> <span class="variable">in</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">FileInputStream</span>(<span class="keyword">new</span></span><br><span class="line"><span class="title class_">File</span>(<span class="string">&quot;e:/lagou.txt&quot;</span>));</span><br><span class="line"><span class="comment">//2 准备好写出数据到hdfs的输出流</span></span><br><span class="line"><span class="keyword">final</span> <span class="type">FSDataOutputStream</span> <span class="variable">out</span> <span class="operator">=</span> fs.create(<span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/lagou.txt&quot;</span>), <span class="keyword">new</span></span><br><span class="line"><span class="title class_">Progressable</span>() &#123;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">progress</span><span class="params">()</span> &#123; <span class="comment">//这个progress方法就是每传输64KB（packet）就会执行一次，</span></span><br><span class="line">System.out.println(<span class="string">&quot;&amp;&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line">&#125;);</span><br><span class="line"><span class="comment">//3 实现流拷贝</span></span><br><span class="line">IOUtils.copyBytes(in, out, configuration); <span class="comment">//默认关闭流选项是true，所以会自动关闭</span></span><br><span class="line"><span class="comment">//4 关流  可以再次关闭也可以不关了</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><h4 id="NN和SNN"><a href="#NN和SNN" class="headerlink" title="NN和SNN"></a>NN和SNN</h4><p>元数据管理流程图:<br><img src="/../img/bigData/snn_nn.png" alt="SNN和NN"></p><ol><li><p>NN(NameNode)</p><ul><li><p>NN是整个文件系统的管理节点（上传、下载、更改、删除）。它维护着整个文件系统的文件目录树，文件&#x2F;目录的元数据(meta data)和每个文件对应的数据块列表。接收用户的操作请求。</p></li><li><p>文件包括：</p><ul><li>fsimage: 元数据镜像文件。存储某一个时刻的NameNode内元数据信息</li><li>edits: 操作日志文件，NameNode启动后一些新增元信息日志。</li><li>fstime: 保存最近异常checkpoint的时间</li></ul></li><li><p>以上文件时保存在Linux的文件系统中。</p><ul><li>hdfs-site.xml的dfs.namenode.name.dir属性</li></ul></li></ul></li><li><p>SNN(Secondary NameNode)</p><ul><li>作用:<ul><li>辅助NN: SNN不是NN的热备份，而是辅助NN处理FSimage(文件系统的元数据)和Edits(记录了对文件系统所做更改的日志)。</li><li>合并edits和Fsimage: 定期合并fsimage和edits，减少NN重启时恢复文件系统状态的时间。合并过程称为<strong>Checkpoint</strong></li><li>减小NN的负担：通过定期创建Fsimage的检查点，SNN减轻了NN的内存和存储压力</li><li>灾难恢复：在NN发生故障时，SNN中的数据可以用于恢复文件系统的状态，虽然这不是它的主要目的。<br>  <strong>注意</strong>：SNN不是NN的热备份，他不能在NN故障时自动接管其职责。在hadoop2.x版本中，为了提供更高的可用性和灾难恢复能力，引入了HA(高可用性)架构，其中包括使用Active&#x2F;Standby两个NN</li></ul></li></ul></li><li><p>元数据管理流程图:<br><img src="/../img/bigData/snn_nn.png" alt="SNN和NN"><br>根据上图，可知NN和SNN的工作流程为：</p><ol><li>第一阶段：NN启动<ul><li>第一次启动NN格式化后，创建Fsimage和Edits文件。如果不是第一次启动，直接加载编辑日志和镜像文件到内存</li><li>客户端对元数据进行增删改的请求</li><li>NN记录操作日志，更新滚动日志</li><li>NN在内存中对数据进行增删查改</li></ul></li><li>第二阶段：SNN工作<ul><li>SNN询问NN是否需要CheckPoint。直接带回NN是否执行检查点操作结果</li><li>SNN请求执行CheckPoint</li><li>NN滚动正在写的Edits日志</li><li>将滚动前的编辑日志和镜像文件拷贝到SNN.</li><li>SNN加载编辑编辑日志和镜像文件到内存，并合并</li><li>生成新的镜像文件fsimage.checkpoint</li><li>拷贝fsimage.chkpoint到NN</li><li>NN 将fsimage.chkpoint重新命名为fsimage</li></ul></li></ol></li><li><p>CheckPoint</p><ol><li>fs.checkpoint.period指定两次CheckPoint的最大时间间隔默认为3600秒(1个小时)</li><li>fs.checkpoint.size规定edits文件的最大值，一旦超过这个值则强制checkpoint,不管是否到达最大时间间隔，默认是64M<br> [hdfs-default.xml]<pre><code class="xml">&lt;!-- 定时一小时 --&gt;    &lt;property&gt;    &lt;name&gt;dfs.namenode.checkpoint.period&lt;/name&gt;    &lt;value&gt;3600&lt;/value&gt;    &lt;/property&gt;    &lt;!-- 一分钟检查一次操作次数，当操作次数达到1百万时，SecondaryNameNode执行一次 --&gt;    &lt;property&gt;    &lt;name&gt;dfs.namenode.checkpoint.txns&lt;/name&gt;    &lt;value&gt;1000000&lt;/value&gt;    &lt;description&gt;操作动作次数&lt;/description&gt;    &lt;/property&gt;    &lt;property&gt;    &lt;name&gt;dfs.namenode.checkpoint.check.period&lt;/name&gt;    &lt;value&gt;60&lt;/value&gt;    &lt;description&gt; 1分钟检查一次操作次数&lt;/description&gt;    &lt;/property &gt;</code></pre></li></ol></li></ol><h2 id="HBase"><a href="#HBase" class="headerlink" title="HBase"></a>HBase</h2><h3 id="HBase读流程"><a href="#HBase读流程" class="headerlink" title="HBase读流程"></a>HBase读流程</h3><p>简略图1<br><img src="/../img/bigData/hbase_read.png" alt="Hbase_read"><br>图2<br><img src="/../img/bigData/hbase_read2.png" alt="Hbase_read2"></p><ol><li><p>首先从zk表找到meta表的region位置，然后读取meta表中的数据，meta表中存储了用户表的region信息</p></li><li><p>根据要查询的namespace、表名和rowkey信息。找到写入数据对应的region信息</p></li><li><p>找到这个region对应的regionServer,然后发送请求。</p></li><li><p>查找对应的region</p></li><li><p>先从metastore查找数据，如果没有，再从BlockCache上获取<br>HBase上RegionServer的内存分为两个部分</p><ul><li>一部分作为Memstore，主要用来写；</li><li>另外一部分作为BlockCache, 主要用于读数据；</li></ul></li><li><p>如果BlockCache中没有找到，再到StoreFile上进行读取。从StoreFile中读取到数据之后，不是直接把结果数据返回给客户端，而是把数据先写入到BlockCache中，目的是为了加快后续的查询；然后在返回结果给客户端。</p></li></ol><h3 id="HBase写流程"><a href="#HBase写流程" class="headerlink" title="HBase写流程"></a>HBase写流程</h3><p>简略图1<br><img src="/../img/bigData/hbase_write.png" alt="hbase_write"><br>图2<br><img src="/../img/bigData/hbase_write2.png" alt="hbase_write2"></p><ol><li>首先从zk找到meta表的region位置，然后读取meta表中的数据，meta中存储了用户表的region信息</li><li>根据namespace、表名和rowkey信息。找到写入数据库对应的region信息</li><li>找到这个region对应的regionServer，然后发送请求</li><li>把数据分别写到HLog(write ahead log) 和metastore各一份</li><li>memstore达到阈值后把数据刷到磁盘，生成storeFile文件</li><li>删除HLog中的历史数据</li></ol><h2 id="资源调度YARN"><a href="#资源调度YARN" class="headerlink" title="资源调度YARN"></a>资源调度YARN</h2><p>Apache Hadoop YARN是 Hadoop的子项目，为分离Hadoop2.0资源管理和计算组件而引入，是一个资源调度平台，负责为运算程序提供服务器运算资源，相当于一个分布式的操作系统平台，而MapReduce等运算程序则相当于运行于操作系统之上的应用程序。<br>关于 YARN,有几点需要明白的是：</p><ol><li>实际上，YARN并不清楚用户所提交程序的运行机制是什么；</li><li>YARN只负责提供运算资源的调度(用户程序向YARN申请资源，YARN就负责分配资源)</li><li>YARN中的主管角色是<strong>ResourceManager</strong>，而具体提供运算资源的角色是<strong>NodeManager</strong></li><li>YARN框架与运行的用户程序完全解耦，这就意味着在YARN上面可以运行各种类型的分布式运算程序(MR只是其中的一种)，如strom程序、spark程序……</li><li>YARN就是一个通用的资源调度平台，企业中以前存在的各种运算集群都可以整合在一个物理集群上，提高资源利用率，方便数据共享。</li></ol><h3 id="YARN架构"><a href="#YARN架构" class="headerlink" title="YARN架构"></a>YARN架构</h3><p><img src="/../img/bigData/yarn_arch1.png" alt="YARN_acrh"><br><img src="/../img/bigData/yarn_arch2.png" alt="yarn_arch1"></p><ol><li>ResourceManager(RM)：处理客户端请求、启动&#x2F;监控ApplicationMaster、监控NodeManager、资源分配与调度</li><li>NodeManager(NM)：单个节点上的资源管理、处理来自ResourceManager的命令、处理来自ApplicationMaster的命令</li><li>ApplicationMaster(am)：数据切分、为应用程序申请资源、并分配给内部任务、任务监控与容错。</li><li>Conatiner：对任务运行环境的抽象、封装了CPU、内存等多维资源以及环境变量、启动命令等任务运行相关的信息</li></ol><h3 id="YARN工作机制"><a href="#YARN工作机制" class="headerlink" title="YARN工作机制"></a>YARN工作机制</h3><p><img src="/../img/bigData/yarn_work.png" alt="yarn_work"></p><ul><li>作业提交<ol><li>Client调用job.waitForCompletion方法，向整个集群提交MR作业</li><li>Client向RM申请一个作业id</li><li>RM给Client返回该job资源的提交路径和作业id</li><li>Client提供jar包，切片信息和配置文件到指定的资源提交路径</li><li>Client提交完资源后，向RM申请运行MrAppMaster</li></ol></li><li>作业初始化<ol start="6"><li>当RM收到Client的请求后，将该job添加到容量调度器中。</li><li>某一个空闲的NM领取到Job</li><li>该NM创建Container,并产生MRAppMaster</li><li>下载Client提交的资源到本地</li></ol></li><li>任务分配<ol start="10"><li>MRAppMaster向RM申请运行多个MapTask任务资源</li><li>RM将运行MapTask任务分配给另外两个NodeManager,另外两个NodeManager分别领取任务并创建容器</li></ol></li><li>任务运行<ol start="12"><li>MR向两个接收到任务的NodeManager发送程序启动脚本，这两个NodeManager分别启动MapTask.MapTask对数据分区排序</li><li>MrAppMaster等待所有MapTask运行完毕后，向RM申请容器，运行ReduceTask.</li><li>ReduceTask向MapTask获取相应分区的数据</li><li>程序运行完毕后，MR会向RM申请注销自己</li></ol></li><li>进度和状态更新<br>  YARN中的任务将其进度和状态返回给应用管理器，客户端每秒(通过mapreduce.client.progressmonitor.pollinterval设置)向应用管理器请求进度更新，展示给用户</li><li>作业完成<br>  除了向应用管理器请求作业进度外，客户端每5秒都会通过调用waitForCompletion()来检查作业是否完成。时间间隔可以通过mapreduce.client.completion.pollinterval来设置。作业完成之后，应用管理器和Container会清理工作状态。作业的信息会被作业历史服务器存储以备之后用户核查</li></ul><h3 id="YARN生命周期"><a href="#YARN生命周期" class="headerlink" title="YARN生命周期"></a>YARN生命周期</h3><p><img src="/../img/bigData/yarn_lifetime.png" alt="yarn_lifetime"></p><h2 id="Zookeeper"><a href="#Zookeeper" class="headerlink" title="Zookeeper"></a>Zookeeper</h2><h3 id="Zookeeper是什么？"><a href="#Zookeeper是什么？" class="headerlink" title="Zookeeper是什么？"></a>Zookeeper是什么？</h3><p>Zookeeper是一个分布式协调服务的开源框架。主要用来解决<strong>分布式集群中应用系统的一致性问题</strong>，例如怎样避免同时操作同一数据造成脏读的问题。分布式系统中数据存在一致性的问题！！  </p><ul><li><strong>ZooKeeper本质上是一个分布式的小文件存储系统</strong>。提供基于类似于文件系统的目录树方式的数据存储，并且可以对树中的节点进行有效管理。</li><li><strong>Zookeeper提供给客户端监控存储在zk内部数据的功能</strong>，从而可以达到基于数据的集群管理。诸如：统⼀命名服务(dubbo)、分布式配置管理(solr的配置集中管理)、分布式消息队列<br>（sub&#x2F;pub）、分布式锁、分布式协调等功能。</li></ul><h3 id="Zookeeper的架构组成"><a href="#Zookeeper的架构组成" class="headerlink" title="Zookeeper的架构组成"></a>Zookeeper的架构组成</h3><p><img src="/../img/bigData/zookper1.png" alt="zookeeper"></p><ol><li><strong>Leader</strong>:  <ul><li>Zookeeper 集群⼯作的核⼼⻆⾊</li><li>集群内部各个服务器的调度者。</li><li>事务请求（写操作） 的<strong>唯⼀调度和处理者</strong>，保证集群事务处理的顺序性；对于 create，<br>setData， delete 等有写操作的请求，则需要统⼀转发给leader 处理， leader 需要决定编号、执⾏操作，这个过程称为⼀个事务。</li></ul></li><li><strong>Follower</strong>:<ul><li>处理客户端⾮事务（读操作） 请求，</li><li>转发事务请求给 Leader；</li><li>参与集群 Leader 选举投票 2n-1台可以做集群投票。</li></ul></li></ol><p>此外，针对访问量⽐较⼤的 zookeeper 集群， 还可新增观察者⻆⾊。  </p><ol start="3"><li><strong>Observer</strong>:<ul><li>观察者⻆⾊，观察 Zookeeper 集群的最新状态变化并将这些状态同步过来，其对于⾮事务请求可以进行独⽴处理，对于事务请求，则会转发给 Leader服务器进⾏处理。</li><li>不会参与任何形式的投票只提供⾮事务服务，通常⽤于在不影响集群事务处理能⼒的前提下提升集群的⾮事务处理能⼒。增加了集群增加并发的读请求。</li></ul></li></ol><p><img src="/../img/bigData/zookper2.png" alt="zookper2"></p><h3 id="Zookeeper的工作特点"><a href="#Zookeeper的工作特点" class="headerlink" title="Zookeeper的工作特点"></a>Zookeeper的工作特点</h3><ol><li>Zookeeper：⼀个领导者（leader:⽼⼤），多个跟随者（follower:⼩弟）组成的集群。</li><li>Leader负责进⾏投票的发起和决议，更新系统状态(内部原理)</li><li>Follower⽤于接收客户请求并向客户端返回结果，在选举Leader过程中参与投票</li><li>集群中只要有半数以上节点存活，Zookeeper集群就能正常服务。</li><li>全局数据⼀致：每个server保存⼀份相同的数据副本，Client⽆论连接到哪个server，数据都是⼀<br>致的。</li><li>更新请求顺序进⾏(内部原理)</li><li>数据更新原⼦性，⼀次数据更新要么成功，要么失败。</li></ol><h3 id="Zookeeper数据结构与监听机制"><a href="#Zookeeper数据结构与监听机制" class="headerlink" title="Zookeeper数据结构与监听机制"></a>Zookeeper数据结构与监听机制</h3><p><strong>ZooKeeper数据模型Znode</strong>：<br>在ZooKeeper中，数据信息被保存在⼀个个数据节点上，这些节点被称为znode。ZNode 是<br>Zookeeper 中最⼩数据单位，在 ZNode 下⾯⼜可以再挂 ZNode，这样⼀层层下去就形成了⼀个层次化<br>命名空间 ZNode 树，我们称为 ZNode Tree，它采⽤了类似⽂件系统的层级树状结构进⾏管理。⻅下图<br>示例：<br><img src="/../img/bigData/zookeeper_znode1.png" alt="zookeeper_znode1"></p><p>在 Zookeeper 中，每⼀个数据节点都是⼀个 ZNode，上图根⽬录下有两个节点，分别是：app1 和<br>app2，其中 app1 下⾯⼜有三个⼦节点,所有ZNode按层次化进⾏组织，形成这么⼀颗树，ZNode的节<br>点路径标识⽅式和Unix⽂件系统路径⾮常相似，都是由⼀系列使⽤斜杠（&#x2F;）进⾏分割的路径表示，开<br>发⼈员可以向这个节点写⼊数据，也可以在这个节点下⾯创建⼦节点。</p><h4 id="ZNode的类型"><a href="#ZNode的类型" class="headerlink" title="ZNode的类型"></a>ZNode的类型</h4><p>Zookeeper 节点类型可以分为三⼤类：</p><ul><li>持久性节点（Persistent）</li><li>临时性节点（Ephemeral）</li><li>顺序性节点（Sequential）</li></ul><p>在开发中在创建节点的时候通过组合可以⽣成以下四种节点类型：<strong>持久节点、持久顺序节点、临时节<br>点、临时顺序节点</strong>。不同类型的节点则会有不同的⽣命周期：</p><ul><li>持久节点：是Zookeeper中最常⻅的⼀种节点类型，所谓持久节点，就是指节点被创建后会⼀直存在服<br>务器，直到删除操作主动清除</li><li>持久顺序节点：就是有顺序的持久节点，节点特性和持久节点是⼀样的，只是额外特性表现在顺序上。<br>顺序特性实质是在创建节点的时候，会在节点名后⾯加上⼀个数字后缀，来表示其顺序。</li><li>临时节点：就是会被⾃动清理掉的节点，它的⽣命周期和客户端会话绑在⼀起，客户端会话结束，节点<br>会被删除掉。与持久性节点不同的是，临时节点不能创建⼦节点。</li><li>临时顺序节点：就是有顺序的临时节点，和持久顺序节点相同，在其创建的时候会在名字后⾯加上数字后缀。</li><li><strong>事务ID</strong><br>⾸先，先了解，事务是对物理和抽象的应⽤状态上的操作集合。往往在现在的概念中，ሀ义上的事务通<br>常指的是数据库事务，⼀般包含了⼀系列对数据库有序的读写操作，这些数据库事务具有所谓的ACID特<br>性，即原⼦性（Atomic）、⼀致性（Consistency）、隔离性（Isolation）和持久性（Durability）。<br>⽽在ZooKeeper中，事务是指能够改变ZooKeeper服务器状态的操作，我们也称之为事务操作或更新<br>操作，⼀般包括数据节点创建与删除、数据节点内容更新等操作。对于每⼀个事务请求，ZooKeeper都<br>会为其分配⼀个全局唯⼀的事务ID，⽤ ZXID 来表示，通常是⼀个 64 位的数字。每⼀个 ZXID 对应⼀次<br>更新操作，从这些ZXID中可以间接地识别出ZooKeeper处理这些更新操作请求的全局顺序。<br>zk中的事务指的是对zk服务器状态改变的操作(create,update data,更新字节点)；zk对这些事务操作都<br>会编号，这个编号是⾃增⻓的被称为ZXID。</li></ul><h4 id="Watcher机制-观察者模式"><a href="#Watcher机制-观察者模式" class="headerlink" title="Watcher机制 (观察者模式)"></a>Watcher机制 (观察者模式)</h4><p>Zookeeper使⽤Watcher机制实现分布式数据的发布&#x2F;订阅功能，⼀个典型的发布&#x2F;订阅模型系统定义了⼀种、⼀对多的订阅关系，能够让多个订阅者同时监听某⼀个主题<br>对象，当这个主题对象⾃身状态变化时，会通知所有订阅者，使它们能够做出相应的处理。<br>在 ZooKeeper 中，引⼊了 Watcher 机制来实现这种分布式的通知功能。<strong>ZooKeeper 允许客户端向服务端注册⼀个 Watcher 监听</strong>，当服务端的⼀些指定事件触发了这个 Watcher，那么Zk就会向指定客户端<br>发送⼀个事件通知来实现分布式的通知功能。</p><p>整个Watcher注册与通知过程如图所示。<br><img src="/../img/bigData/zookeeper_watcher.png" alt="zookeeper_watcher">  </p><p>Zookeeper的Watcher机制主要包括<strong>客户端线程、客户端WatcherManager、Zookeeper服务器</strong>三部<br>分。<br>具体⼯作流程为：</p><ul><li>客户端在向Zookeeper服务器注册的同时，会将Watcher对象存储在客户端的WatcherManager当<br>中</li><li>当Zookeeper服务器触发Watcher事件后，会向客户端发送通知</li><li>客户端线程从WatcherManager中取出对应的Watcher对象来执⾏回调逻辑</li></ul><h3 id="Zookeeper内部原理"><a href="#Zookeeper内部原理" class="headerlink" title="Zookeeper内部原理"></a>Zookeeper内部原理</h3><h4 id="Leader选举"><a href="#Leader选举" class="headerlink" title="Leader选举"></a>Leader选举</h4><ol><li><p>选举机制</p><ul><li>半数机制：集群中半数以上机器存活，集群可⽤。所以Zookeeper适合安装奇数台服务器。</li><li>Zookeeper虽然在配置⽂件中并没有指定Master和Slave。但是，Zookeeper⼯作时，是有⼀个节点为Leader，其它为Follower，Leader是通过内部的选举机制产⽣的。</li></ul></li><li><p>集群⾸次启动<br>假设有五台服务器组成的Zookeeper集群，它们的id从1-5，同时它们都是最新启动的，也就是没有历史<br>数据，在存放数据量这⼀点上，都是⼀样的。假设这些服务器依序启动，来看看会发⽣什么，<br><img src="/../img/bigData/hadoop1.png" alt="zookeeper_leader"><br>Zookeeper的选举机制<br>（1）服务器1启动，此时只有它⼀台服务器启动了，它发出去的报⽂没有任何响应，所以它的选举状态<br>⼀直是LOOKING状态。<br>（2）服务器2启动，它与最开始启动的服务器1进⾏通信，互相交换⾃⼰的选举结果，由于两者都没有<br>历史数据，所以id值较⼤的服务器2胜出，但是由于没有达到超过半数以上的服务器都同意选举它(这个<br>例⼦中的半数以上是3)，所以服务器1、2还是继续保持LOOKING状态。<br>（3）服务器3启动，根据前⾯的理论分析，服务器3成为服务器1、2、3中的⽼⼤，⽽与上⾯不同的<br>是，此时有三台服务器选举了它，所以它成为了这次选举的Leader。<br>（4）服务器4启动，根据前⾯的分析，理论上服务器4应该是服务器1、2、3、4中最⼤的，但是由于前<br>⾯已经有半数以上的服务器选举了服务器3，所以它只能接收当⼩弟的命了。<br>（5）服务器5启动，同4⼀样称为follower。</p></li><li><p>集群⾮⾸次启动<br>每个节点在选举时都会参考⾃身节点的zxid值（事务ID）；优先选择zxid值⼤的节点称为Leader!!</p></li></ol><h4 id="ZAB⼀致性协议"><a href="#ZAB⼀致性协议" class="headerlink" title="ZAB⼀致性协议"></a>ZAB⼀致性协议</h4><p>ZK就是分布式⼀致性问题的⼯业解决⽅案，paxos是其底层理论算法(晦涩难懂著名)，其中zab，raft和<br>众多开源算法是对paxos的⼯业级实现。ZK没有完全采⽤paxos算法，⽽是使⽤了⼀种称为Zookeeper<br>Atomic Broadcast（ZAB，Zookeeper原⼦消息⼴播协议）的协议作为其数据⼀致性的核⼼算法。<br><strong>ZAB协议</strong><br>ZAB 协议是为分布式协调服务 Zookeeper 专⻔设计的⼀种⽀持崩溃恢复和原⼦⼴播协议。<br><strong>主备模式保证⼀致性</strong><br><img src="/../img/bigData/zab.png" alt="ZAB"><br>ZK怎么处理集群中的数据？所有客户端写⼊数据都是写⼊Leader中，然后，由 Leader 复制到Follower<br>中。ZAB会将服务器数据的状态变更以事务Proposal的形式⼴播到所有的副本进程上，ZAB协议能够保<br>证了事务操作的⼀个全局的变更序号(ZXID)。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;大数据原理期末复习&quot;&gt;&lt;a href=&quot;#大数据原理期末复习&quot; class=&quot;headerlink&quot; title=&quot;大数据原理期末复习&quot;&gt;&lt;/a&gt;大数据原理期末复习&lt;/h1&gt;&lt;h2 id=&quot;Hadoop&quot;&gt;&lt;a href=&quot;#Hadoop&quot; class=&quot;head</summary>
      
    
    
    
    <category term="学习总结" scheme="https://gyhpcg.gihthub.io/categories/%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    
    
    <category term="big data" scheme="https://gyhpcg.gihthub.io/tags/big-data/"/>
    
  </entry>
  
  <entry>
    <title>设计模式</title>
    <link href="https://gyhpcg.gihthub.io/2023/11/23/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    <id>https://gyhpcg.gihthub.io/2023/11/23/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/</id>
    <published>2023-11-23T10:22:05.000Z</published>
    <updated>2023-11-23T11:55:37.861Z</updated>
    
    <content type="html"><![CDATA[<h1 id="设计模式"><a href="#设计模式" class="headerlink" title="设计模式"></a>设计模式</h1><h2 id="一-设计模式六大原则"><a href="#一-设计模式六大原则" class="headerlink" title="一. 设计模式六大原则"></a>一. 设计模式六大原则</h2><p>总原则–开闭原则</p><blockquote><p>一个软件实体一个对扩展开放，对修改关闭</p></blockquote><ol><li>单一职责原则<blockquote><p>一个类应该只有一个引起发生变化的原因</p></blockquote></li><li>里氏替换原则<blockquote><p>所有使用父类的地方都可以用子类对象来替换（子类对父类的方法尽量不要重写和重载）</p></blockquote></li><li>依赖倒转原则<blockquote><ol><li>上层模块不应该依赖底层模块，它们都应该依赖抽象</li><li>抽象不应该依赖于细节，细节应该依赖于抽象</li></ol></blockquote></li><li>接口隔离原则<blockquote><ol><li>客户端不应该依赖它不需要的接口</li><li>类间的依赖关系应该建立在最小的接口上</li></ol></blockquote></li><li>迪米特原则（最小知道原则）<blockquote><p>只与你的直接朋友交谈，不跟“陌生人”说话<br>一个类对自己依赖的类知道的越少越好。无论被依赖的类多么复杂，都应该将逻辑封装在方法的内部，通过public 方法提供给外部</p></blockquote></li><li>合成复用原则（组合优先于继承）<blockquote><p>尽量使用对象组合&#x2F;聚合，而是继承关系达到软件复用的目的</p></blockquote></li></ol><h2 id="二-设计模式的三大类"><a href="#二-设计模式的三大类" class="headerlink" title="二. 设计模式的三大类"></a>二. 设计模式的三大类</h2><ol><li>创建型模式：对类的实例化过程进行了抽象，能够将软件模块中对象的创建和对象的使用分离。工厂模式、抽象工厂模式、单例模式、建造者模式、原型模式</li><li>结构型模式：关注于对象的组成以及对象之间的依赖关系，描述如何将类或者对象结合在一起形成更大的结构，就像搭积木，可以通过简单积木的组合形成复杂的、功能更为强大的结构。 适配器模式、装饰者模式、代理模式、外观模式、桥接模式、组合模式、享元模式。</li><li>行为型模式：关注于对象的行为问题，是对在不同的对象之间划分责任和算法的抽象化；不仅仅关注类和对象的结构，而且重点关注它们之间的相互作用。<blockquote><p>策略模式、模板方法模式、观察者模式、迭代器模式、责任链模式、命令模式、备忘录模式、状态模式、访问者模式、中介者模式、解释器模式</p></blockquote></li></ol><h2 id="三-23种设计模式"><a href="#三-23种设计模式" class="headerlink" title="三. 23种设计模式"></a>三. 23种设计模式</h2>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;设计模式&quot;&gt;&lt;a href=&quot;#设计模式&quot; class=&quot;headerlink&quot; title=&quot;设计模式&quot;&gt;&lt;/a&gt;设计模式&lt;/h1&gt;&lt;h2 id=&quot;一-设计模式六大原则&quot;&gt;&lt;a href=&quot;#一-设计模式六大原则&quot; class=&quot;headerlink&quot; titl</summary>
      
    
    
    
    <category term="学习总结" scheme="https://gyhpcg.gihthub.io/categories/%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    
    
    <category term="设计模式" scheme="https://gyhpcg.gihthub.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>hexo搭建测试</title>
    <link href="https://gyhpcg.gihthub.io/2023/11/06/hexo%E6%90%AD%E5%BB%BA%E6%B5%8B%E8%AF%95/"/>
    <id>https://gyhpcg.gihthub.io/2023/11/06/hexo%E6%90%AD%E5%BB%BA%E6%B5%8B%E8%AF%95/</id>
    <published>2023-11-06T04:57:10.000Z</published>
    <updated>2023-11-06T05:23:35.482Z</updated>
    
    <content type="html"><![CDATA[<h1 id="first-test"><a href="#first-test" class="headerlink" title="first test"></a>first test</h1><h1 id="second-test"><a href="#second-test" class="headerlink" title="second test"></a>second test</h1><h2 id="hello-test"><a href="#hello-test" class="headerlink" title="hello test"></a>hello test</h2>]]></content>
    
    
    <summary type="html">关于hexo搭建的一些测试</summary>
    
    
    
    
    <category term="environment" scheme="https://gyhpcg.gihthub.io/tags/environment/"/>
    
  </entry>
  
  <entry>
    <title>2023rcore第二阶段学习总结</title>
    <link href="https://gyhpcg.gihthub.io/2023/11/05/rcore_study/"/>
    <id>https://gyhpcg.gihthub.io/2023/11/05/rcore_study/</id>
    <published>2023-11-05T15:09:21.000Z</published>
    <updated>2023-11-06T13:12:55.447Z</updated>
    
    <content type="html"><![CDATA[<h1 id="2023rcore第二阶段学习总结和个人与计算机系统的漫游"><a href="#2023rcore第二阶段学习总结和个人与计算机系统的漫游" class="headerlink" title="2023rcore第二阶段学习总结和个人与计算机系统的漫游"></a>2023rcore第二阶段学习总结和个人与计算机系统的漫游</h1><h2 id="初识"><a href="#初识" class="headerlink" title="初识"></a>初识</h2><p>与 <a href="https://github.com/LearningOS">rcore开源操作系统训练营</a> 的相识，算是一个很偶然的机会吧。我与计算机结识很晚，在我上大学后，才从一个对计算机连打字都不会的人到慢慢熟练使用以及熟悉各种技术的人。与操作系统(Linux)结识，是大一下学期的 计算机系统基础课(教程是那本鼎鼎大名的 <strong>深入了解计算机系统</strong>)，那节课开启了我Linux的漫游旅途。</p><h2 id="兴趣"><a href="#兴趣" class="headerlink" title="兴趣"></a>兴趣</h2><p>在我刚接触计算机的时候，一直认为开发出一个web网站或者APP，就是一件特别特别酷的事情。在整个刚接触计算机的事情，写出一个web网页或者APP便是我一直想要做的事。但后来，大一结束的暑假，学习了一些这方面的技术，扒开了web的真实面目，便慢慢失去了很多兴趣，曾经很酷的事情，突然感觉很无味了。所幸的是，在这个时候，学校的 <strong>OS</strong> 课开了，杨老师是一名非常知识渊博、热爱体系结构的老师，他 <strong>OS</strong> 第一门课留给我们的作业便是</p><blockquote><p>下载linux内核源码，并往内核中添加自定义系统调用</p></blockquote><p>这算是我开启了我正式与操作系统内核接触的旅途。永远无法忘却第一次下载linux内核源码，然后编译的时候，满屏报错的电脑界面，特别是每次编译的时候，都会让我等待很久，几乎每次都是编译了三十多分钟，然后给我报错，如此循环往复……最后终于把代码编译完成。第一次进入<strong>kernel</strong> 目录下，进入代码里面，映入眼帘的是 <strong>Linus Torvalds</strong> 的大名，那是我第二次那么激动(第一次激动的时候是第一次敲出 “Hello, World”)。最后在各种操作之下，各种文件之间来回修改的条件下，我终于让自己自定义的一个系统调用成功运行了起来，那一瞬间，像是打开了潘多拉的魔盒，从此我开始对体系结构、操作系统方向的东西产生了很大兴趣，便也萌生了写一个OS的想法，从此整个想法，便一直根深蒂固着。</p><h2 id="遇见rcore"><a href="#遇见rcore" class="headerlink" title="遇见rcore"></a>遇见rcore</h2><p>诚恳的说，我是因为心中那个根深蒂固的想法才会有机会遇见rcore，刚开始的时候，我其实知道的是 <strong>ucore</strong>, 后来因为个人非常喜欢c++，而某段的时间里，网上的各样信息都在告诉我 <strong>Rust</strong> 是c++的强大竞争者，<strong>Rust</strong> 是如何的安全，如何的高效。便萌发了我对这一门新型语言的兴趣。</p><h3 id="Rust"><a href="#Rust" class="headerlink" title="Rust:"></a>Rust:</h3><p>第一次用Rust的时候，它的cargo便惊艳了我很久，用c++的时候，每次安装第三方包，亦或是换个平台，编译东西，都会让我折磨很久，总是在各种编译器之间的实现困惑，msvc有的特性，在gcc有时候却无法运行，有时候在gcc能够运行的东西，在clang也无法运行。同样让人痛苦的时候，c++20&#x2F;c++23都出了很久了，但是不同编译器的支持却是层出不穷……。换到Rust，突然很多东西便让人清爽了许多。也便逐渐开始了学习Rust的旅途。</p><h3 id="risc-v"><a href="#risc-v" class="headerlink" title="risc-v:"></a>risc-v:</h3><p>对于risc-v的了解，在开始rcore之前，我也只知道它是开源的，文档内容少(远没有X86和Arm那样内容复杂和繁冗)。后来了解了一下龙芯，<a href="https://oscpu.github.io/ysyx/">一生一芯</a>等，便也对risc-v有了极大兴趣，恰逢此时，rcore便出现在了我面前。</p><h3 id="rcore"><a href="#rcore" class="headerlink" title="rcore:"></a>rcore:</h3><p><a href="https://rcore-os.cn/rCore-Tutorial-Book-v3/index.html">rcore Book</a> 的娓娓道来，特别是以各种史前生物 来描述，增加了一番故事书的趣味。而<a href="http://learningos.cn/rCore-Tutorial-Guide-2023A/">Guide</a>则能够快速地让我明白了代码地框架，每个文件，每个模块是什么样的功能。但无奈个人基础不好，所以大部分时间还是在看 Book。本次实验让我们实现操作系统核心的几个重要功能：</p><ol><li>多到程序与分时多道任务</li></ol><ul><li>Lab1 需要完善系统调用。对于 sys_task_info 系统调用，我们在 TCP 添加相应字段处理即<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">sys_task_info</span>(ti: *<span class="keyword">mut</span> TaskInfo) <span class="punctuation">-&gt;</span> <span class="type">isize</span> &#123;</span><br><span class="line">        <span class="keyword">unsafe</span>&#123;</span><br><span class="line">        *ti = TaskInfo&#123;</span><br><span class="line">            status:<span class="title function_ invoke__">get_current_status</span>(),</span><br><span class="line">            syscall_times:<span class="title function_ invoke__">get_syscall_times</span>(),</span><br><span class="line">            time : (<span class="title function_ invoke__">get_time_us</span>() - <span class="title function_ invoke__">get_current_start_time</span>()) / <span class="number">1000</span></span><br><span class="line"></span><br><span class="line">        &#125;;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="number">0</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><ol start="2"><li><p>虚拟内存管理  </p><p> 这部分的内容中，为 Rcore 引入了虚拟内存，为地址空间加上了一层抽象，# 地址空间<br> 刚学计算机的时候，个人非常总喜欢将所有代码放在一个文件里，觉得分开各种代码很是麻烦。后来因为学习深入，开始对分离代码，抽象多了很多体会。特别是在学计算机网络的TCP&#x2F;IP模型和操作系统的时候，对<strong>抽象，加层</strong>的思想确实是不断体会，不断明白了那句话“在计算机中，没有什么是不能加一层解决不了的”。现在来好好感受在ch4中的抽象加一层。</p><ol><li><p>为什么要添加一层抽象层：</p><ul><li>从应用开发的角度看，需要应用程序决定自己会被加载到哪个物理地址运行，需要直接访问真实的物理内存。这就要求应用开发者对于硬件的特性和使用方法有更多了解，产生额外的学习成本，也会为应用的开发和调试带来不便</li><li>从内核的角度来看，将直接访问物理内存的权力下放到应用会使得它难以对应用程序的访存行为进行有效管理，已有的特权级机制亦无法阻止很多来自应用程序的恶意行为。</li></ul></li><li><p>该抽象层要完成的目标：</p><ul><li><p>透明 ：应用开发者可以不必了解底层真实物理内存的硬件细节，且在非必要时也不必关心内核的实现策略， 最小化他们的心智负担；</p></li><li><p>高效 ：这层抽象至少在大多数情况下不应带来过大的额外开销；</p></li><li><p>安全 ：这层抽象应该有效检测并阻止应用读写其他应用或内核的代码、数据等一系列恶意行为。</p></li></ul></li></ol></li><li><p>进程管理</p><ul><li>对于进程、程序、可执行文件等的了解更加深入了<ol><li>进程是在操作系统管理下的程序的一次执行过程，程序是一个静态的概念。</li><li>可执行文件是一张“蓝图”：一张编译器解析源代码之后总结出的一张记载如何利用各种硬件资源进行一轮生产流程的 <strong>蓝图</strong></li><li>加载同一个可执行文件的两个进程也是不同的：它们的启动时间、占据的硬件资源、输入数据均有可能是不同的，这些条件均会导致它们是不一样的执行过程。</li><li>对于创建进程需要fork()和exec()两个系统调用而不只是一个系统调用。两个组合更加灵活，fork是为了 exec 一个新应用提供空间，然后exec可以读取不同的elf文件，执行不同的操作。</li></ol></li></ul></li><li><p>文件系统(未完待续)</p></li><li><p>并发(未完待续)</p></li></ol><p>但很可惜，因为个人基础和时间还有其他各种各样的原因，个人并没有完成五个实验，前面三个实验也只是勉强完成（虽然运行过了，但还是有很多东西之间还不明白）。接下来的时间，我将好好把先前没有弄明白的知识点再好好梳理一遍。并将继续做完还没有先前没有做完的工作。向训练营各位优秀的同学学习，以后要多写博客，多写博客(这次学到的一个优秀习惯)，及时梳理知识。纸上得来终觉浅，绝知此事要躬行！！！。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;2023rcore第二阶段学习总结和个人与计算机系统的漫游&quot;&gt;&lt;a href=&quot;#2023rcore第二阶段学习总结和个人与计算机系统的漫游&quot; class=&quot;headerlink&quot; title=&quot;2023rcore第二阶段学习总结和个人与计算机系统的漫游&quot;&gt;&lt;/a</summary>
      
    
    
    
    <category term="学习总结" scheme="https://gyhpcg.gihthub.io/categories/%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    
    
    <category term="Rust" scheme="https://gyhpcg.gihthub.io/tags/Rust/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="https://gyhpcg.gihthub.io/2023/11/05/hello-world/"/>
    <id>https://gyhpcg.gihthub.io/2023/11/05/hello-world/</id>
    <published>2023-11-05T14:28:16.264Z</published>
    <updated>2023-11-06T03:22:56.979Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.io/docs/&quot;&gt;documentation&lt;/a&gt; for</summary>
      
    
    
    
    
  </entry>
  
</feed>
