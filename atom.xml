<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>A tour of my learing</title>
  
  <subtitle>All in CS</subtitle>
  <link href="https://gyhpcg.gihthub.io/atom.xml" rel="self"/>
  
  <link href="https://gyhpcg.gihthub.io/"/>
  <updated>2024-01-06T14:59:18.645Z</updated>
  <id>https://gyhpcg.gihthub.io/</id>
  
  <author>
    <name>pancg</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>常用简单工具</title>
    <link href="https://gyhpcg.gihthub.io/2024/01/06/%E5%B8%B8%E7%94%A8%E7%AE%80%E5%8D%95%E5%B7%A5%E5%85%B7/"/>
    <id>https://gyhpcg.gihthub.io/2024/01/06/%E5%B8%B8%E7%94%A8%E7%AE%80%E5%8D%95%E5%B7%A5%E5%85%B7/</id>
    <published>2024-01-06T14:52:37.000Z</published>
    <updated>2024-01-06T14:59:18.645Z</updated>
    
    <content type="html"><![CDATA[<h1 id="常用工具"><a href="#常用工具" class="headerlink" title="常用工具"></a>常用工具</h1>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;常用工具&quot;&gt;&lt;a href=&quot;#常用工具&quot; class=&quot;headerlink&quot; title=&quot;常用工具&quot;&gt;&lt;/a&gt;常用工具&lt;/h1&gt;</summary>
      
    
    
    
    <category term="工具使用" scheme="https://gyhpcg.gihthub.io/categories/%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/"/>
    
    
    <category term="Tools" scheme="https://gyhpcg.gihthub.io/tags/Tools/"/>
    
  </entry>
  
  <entry>
    <title>2023年的胡思乱想</title>
    <link href="https://gyhpcg.gihthub.io/2023/12/31/2023%E5%B9%B4%E7%9A%84%E8%83%A1%E6%80%9D%E4%B9%B1%E6%83%B3/"/>
    <id>https://gyhpcg.gihthub.io/2023/12/31/2023%E5%B9%B4%E7%9A%84%E8%83%A1%E6%80%9D%E4%B9%B1%E6%83%B3/</id>
    <published>2023-12-31T11:55:27.000Z</published>
    <updated>2024-01-06T15:13:19.934Z</updated>
    
    <content type="html"><![CDATA[<h1 id="胡思乱想-一-和-2023总结"><a href="#胡思乱想-一-和-2023总结" class="headerlink" title="胡思乱想(一) 和 2023总结"></a>胡思乱想(一) 和 2023总结</h1><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>其实没有什么好总结的，毕竟微信那里总结过啦<br><img src="/../img/personal_think/weixin2023personal_clusion.png" alt="weixin"><br>2022年12月31号立下的flag成为一个高手，完成四大件。然后到今天，刚好过了整整一年。发现自己大概完成了一半，其实把完成的一半完完整整做好了，就算是一件很好的事情了。但无奈的是，总是很多原因和意外，把完成到一半的进度砍掉。就这样吧。2024年继续完成剩下来的工作，并希望自己永远保持好奇和热情，永远向前。</p><h2 id="胡思乱想"><a href="#胡思乱想" class="headerlink" title="胡思乱想"></a>胡思乱想</h2><h3 id="回顾"><a href="#回顾" class="headerlink" title="回顾"></a>回顾</h3><p>其实这才是重点，关于记录这件事，似乎从小到大就很喜欢写东西，在还没上学前，就已经把家里的墙壁全部写花了。后来上小学，也总喜欢写一些关于个人奇思幻想的东西。如二年级的东西(11月份我老妈刚好把我所有一年级到高中的东西全部丢了，跟我说的时候，我还一度挺伤心的，我一直对于旧事旧物怀揣着一种美化的回忆和一种近乎神圣的感觉，老是想留着……)<br>哎，现状关于过去的东西全部被老妈丢弃了，只剩下两张二年级的图片回忆了<br><img src="/../img/personal_think/2023personal_class_two.jpg" alt="2023personal_class_two"><br><img src="/../img/personal_think/2023personal_class_two1.jpg" alt="2023personal_class_two1"></p><p>小学很喜欢写东西……上初中后，不喜欢写，但由于我的语文老师把日记当作每日作业，迫于这种原因，所以还是不得不继续写。虽然整个初中一直流水账，其实开始写得很好的，但后来日记每次都十几个人拿去抄(毕竟这也是作业)。还有部分女同学还真特别喜欢看我日记……以至于某次被某同学抢日记，去抢回来的时候，被人家抓掉了一块肉(现状那个地方的疤痕依旧很明显……)<br>高中，遇到了文老师（不过我们都叫他”大师”，他经常在自己写的诗词里叫自己或者和他的朋友们以“文子”自称）。在他的感染之下，我再次回归语文的怀抱？不是语文吧，是文学，是诗词和哲学。大师对我的影响很大，他上课的内容从来是课本上20%，扩展80%。依稀记得，上《赤壁赋》的时候，将课本他花了两节课，然后将苏东坡个人事迹，将佛学和儒学、禅宗等讲了一个月。每次都这样，他是一个很喜欢读书的人，每次上课的时候，手上必怀抱着四五本书(每周不重样)，他向我们推荐，规定我们上他课的时候，桌子上必须放有一本他觉得不错的书籍（不然会被他拿书敲）。我们班是理科班，所以他总喜欢说”你们这群没有灵性的……”。但在他影响下，我们班每个人都从不阅读，到很喜欢阅读的状态。我常觉得，我的文学启蒙老师是文老师。文老师带我领略中国传统文学，也带我走在那晦涩的西方哲学，如黑格尔，荷尔德林，海德格尔等，当然还有尼采！！！<br>所以，在高中，我很喜欢写各种各样的读书札记、各种各样的奇思幻想也会写在书本上。所以那时候也很喜欢写东西，很喜欢闻着纸上的那种味道。<br>人生总有各种各样的意外，比如上大学，彻底改变了我的轨迹。我离开了所有我曾经认为我这辈子最喜欢的，不可分割的东西。开始远离了文学，小说、诗词和哲学等。依然记得我最后一次好好读诗词的时候，是在李老师主讲的《古典诗词鉴赏》课上，依然记得上课的时候“这个同学名字不错，起来回答一下”。清楚记得，论述一下你心中的李白，并为他写一首诗。李白，我整个人生最喜欢的诗人，然后不可避免的回答的不错，写的那首诗居然成为了模范作业，哈哈哈哈。后面的李煜，王国维等我也不可避免受到了老师的表扬。。。然后那门课最后的期末作业，我花了心思写。最后结果也很好。但那是我最后一次好好读诗词了。那时候还是大一呢……。此后我便没有再写过东西，也没写过东西(除了平时的签名)。就这样，我远离了自己整个童年和青春时代最喜欢的东西。<br>今年11月参加了清华的Rcore训练营，在里面认识了很多厉害的人，而李老师也要求我们必须写学习总结，写个人感悟等。这样后，我才开始又恢复回了写东西的状态。虽然不再是用笔写了（除了要表明情意等情况下，我才必须亲手写），都是自己打字记录了。</p><h3 id="胡思乱想-1"><a href="#胡思乱想-1" class="headerlink" title="胡思乱想"></a>胡思乱想</h3><p>关于学习，很多人觉得我很喜欢学习……其实不是，只是我刚好很喜欢计算机，高考让我告别了我曾经最喜欢的学科，而现在对于我而言，计算机无疑给了我第二次机会，给了追求自己喜欢的东西，所以我格外的珍惜。其实也不是珍惜，就是单纯的很喜欢，因为喜欢，所以愿意花费我所有的个人时间去了解它，虽然每次结果都会死得很丑。但于我而言，对于自己喜欢的东西，你并不一定要得到一个怎样的结果，你只需要向它努力再努力就行，不要去想什么结果，只要努力去做，享受属于喜欢的每一刻。如此而已。<br>每当我觉得我学到了很多东西，每到了我花费了很多时间去学某些东西时，其结果总会让我恐惧和迷蒙，让我觉得自己太渺小了。我以为我努力学了，对它了解更多了，但每次我都会发现，我不会的东西更多了，我学得越多，我迷惑的也就越多，我的自信心也会变得越来越缺失，我越来越没有自信我能够学好它……。我爬上大树，以为自己站到了最高处，但当我扒开遮住我的树叶时，直入我眼的是一座耸立、无边无际、看不见顶峰的高峰。在它面前，我是如此渺小，是如此弱小，我以为最高的大树在它面前不值一提……。我总是因此而变得情绪低迷，emo一段时间。我知道这个，但我不可避免偶尔绝望……。”生也有涯，而知也无涯”。看的论文越多，也越是感觉自己的浅显……。2023再见，2024希望有个好结果，顺利直博吧！向高山进发！！！</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;胡思乱想-一-和-2023总结&quot;&gt;&lt;a href=&quot;#胡思乱想-一-和-2023总结&quot; class=&quot;headerlink&quot; title=&quot;胡思乱想(一) 和 2023总结&quot;&gt;&lt;/a&gt;胡思乱想(一) 和 2023总结&lt;/h1&gt;&lt;h2 id=&quot;总结&quot;&gt;&lt;a href</summary>
      
    
    
    
    <category term="胡思乱想" scheme="https://gyhpcg.gihthub.io/categories/%E8%83%A1%E6%80%9D%E4%B9%B1%E6%83%B3/"/>
    
    
    <category term="emo胡思乱想" scheme="https://gyhpcg.gihthub.io/tags/emo%E8%83%A1%E6%80%9D%E4%B9%B1%E6%83%B3/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop</title>
    <link href="https://gyhpcg.gihthub.io/2023/12/26/Hadoop/"/>
    <id>https://gyhpcg.gihthub.io/2023/12/26/Hadoop/</id>
    <published>2023-12-26T07:31:28.000Z</published>
    <updated>2023-12-26T08:12:15.697Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Hadoop"><a href="#Hadoop" class="headerlink" title="Hadoop"></a>Hadoop</h1><h2 id="1-大数据简介"><a href="#1-大数据简介" class="headerlink" title="1. 大数据简介"></a>1. 大数据简介</h2><ul><li><p>大数据技术解决的是什么问题？大数据技术解决的主要是海量数据的存储和计算</p></li><li><p>Hadoop的定义：</p><ol><li><strong>狭义</strong>：指的是一个框架，hadoop是由三部分组成：HDFS:分布式文件系统–&gt;存储；MapReduce:分布式离线计算框架–&gt;计算；Yarn：资源调度框架</li><li><strong>广义</strong>：除了Hadoop框架之外还有一些辅助框架。Flume：日志数据采集，Sqoop:关系型数据库的采集； Hive:深度依赖Hadoop框架完成计算(sql)，Hbase：大数据领域的数据库(Mysql); Sqoop：数据的导出 。广义的Hadoop指的是一个生态圈。</li></ol></li><li><p>大数据的定义：<br>  大数据是指无法在一定时间范围内用常规软件工具进行捕捉、管理和处理的数据集合，是需要新处理模式才能具有更强的决策力、洞察发现力和流程优化能力的海量、高增长率和多样化的信息资产。</p><ul><li>特点：5 “V”<ol><li>Volume(大量)</li><li>Velocity(高速)</li><li>Variety(多样)</li><li>Veracity(真实)</li><li>Value(低价廉)</li></ol></li></ul></li><li><p>Hadoop的起源<br>  Google的三篇论文(三驾马车)：  </p><ul><li>GFS:Google的分布式文件系统(Google File System)</li><li>MapReduce:Google的分布式计算框架</li><li>BigTable:大型分布式数据库</li></ul><p>  发展演变关系：</p><ul><li>GFS –&gt; HDFS</li><li>Google MapReduce –&gt; Hadoop MapReduce</li><li>BigTable –&gt; Hbase</li></ul></li><li><p>Hadoop各发行版的区别</p><ol><li>Apache Hadoop:<ul><li>优点：<ol><li>纯粹的开源: Apache Hadoop 是一个开源项目，可以免费获取和使用。</li><li>社区支持: 由于是 Apache 项目，拥有庞大的全球开发者社区，可以获得广泛的支持和反馈。</li><li>定制性: 你可以根据自己的需求和环境定制 Hadoop 的配置和功能。</li></ol></li><li>缺点：<ol><li>缺乏商业支持: Apache Hadoop 不提供官方的商业支持，企业在使用中可能需要依赖社区或第三方支持。</li><li>可能需要更多配置和管理: 由于是原始的 Apache 版本，可能需要更多的配置和管理工作，特别是对于不熟悉 Hadoop 的团队而言。</li></ol></li></ul></li><li>Cloudera CDH:<ul><li>优点： <ol><li>商业支持: Cloudera 提供商业级的技术支持和咨询服务，适用于企业级的生产环境。</li><li>集成的附加组件: CDH 包含许多与 Hadoop 相关的附加组件，如 Impala、Hive、HBase 等，使得构建和管理大数据生态系统更为简单。</li><li>易于安装和管理: Cloudera 提供了一个管理界面，简化了集群的安装、配置和监控。</li></ol></li><li>缺点：<ol><li>收费: Cloudera CDH 是一个商业发行版，使用它的企业需要支付相应的许可费用。</li><li>较大的资源占用: 由于集成了多个组件，CDH 对硬件资源的需求可能相对较高。</li></ol></li></ul></li><li>Hortonworks HDP:<ul><li>优点：<ol><li>开源: Hortonworks HDP 是基于 Apache Hadoop 的开源发行版，可以免费获取和使用。</li><li>商业支持: Hortonworks 提供商业级的支持和服务，包括培训、咨询和技术支持。</li><li>开放性和可扩展性: HDP 是一个相对开放和可扩展的平台，可以与其他开源工具和技术集成。</li></ol></li><li>缺点：<ol><li>竞争压力: 在 Cloudera 吸收 Hortonworks 的过程中，HDP 的未来有一些不确定性。Cloudera 和 Hortonworks 的合并可能会导致一些变化和调整。</li><li>相对较新: 相对于 CDH，HDP 相对较新，可能在一些功能和稳定性方面需要更多的改进。</li></ol></li></ul></li></ol></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Hadoop&quot;&gt;&lt;a href=&quot;#Hadoop&quot; class=&quot;headerlink&quot; title=&quot;Hadoop&quot;&gt;&lt;/a&gt;Hadoop&lt;/h1&gt;&lt;h2 id=&quot;1-大数据简介&quot;&gt;&lt;a href=&quot;#1-大数据简介&quot; class=&quot;headerlink&quot; ti</summary>
      
    
    
    
    <category term="Hadoop" scheme="https://gyhpcg.gihthub.io/categories/Hadoop/"/>
    
    
    <category term="big data" scheme="https://gyhpcg.gihthub.io/tags/big-data/"/>
    
  </entry>
  
  <entry>
    <title>Hive数仓</title>
    <link href="https://gyhpcg.gihthub.io/2023/12/19/Hive%E6%95%B0%E4%BB%93/"/>
    <id>https://gyhpcg.gihthub.io/2023/12/19/Hive%E6%95%B0%E4%BB%93/</id>
    <published>2023-12-19T15:14:30.000Z</published>
    <updated>2023-12-19T15:27:42.152Z</updated>
    
    <content type="html"><![CDATA[<h1 id="数据库-OLTP-和数据仓库-OLAP"><a href="#数据库-OLTP-和数据仓库-OLAP" class="headerlink" title="数据库(OLTP)和数据仓库(OLAP)"></a>数据库(OLTP)和数据仓库(OLAP)</h1><table><thead><tr><th>功能</th><th>数据库</th><th>数据仓库</th></tr></thead><tbody><tr><td>数据1</td><td>数据2</td><td>数据3</td></tr><tr><td>数据4</td><td>数据5</td><td>数据6</td></tr></tbody></table>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;数据库-OLTP-和数据仓库-OLAP&quot;&gt;&lt;a href=&quot;#数据库-OLTP-和数据仓库-OLAP&quot; class=&quot;headerlink&quot; title=&quot;数据库(OLTP)和数据仓库(OLAP)&quot;&gt;&lt;/a&gt;数据库(OLTP)和数据仓库(OLAP)&lt;/h1&gt;&lt;ta</summary>
      
    
    
    
    <category term="big Data" scheme="https://gyhpcg.gihthub.io/categories/big-Data/"/>
    
    
    <category term="Hive" scheme="https://gyhpcg.gihthub.io/tags/Hive/"/>
    
  </entry>
  
  <entry>
    <title>大数据原理技术</title>
    <link href="https://gyhpcg.gihthub.io/2023/12/17/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%8E%9F%E7%90%86%E6%8A%80%E6%9C%AF/"/>
    <id>https://gyhpcg.gihthub.io/2023/12/17/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%8E%9F%E7%90%86%E6%8A%80%E6%9C%AF/</id>
    <published>2023-12-17T07:21:27.000Z</published>
    <updated>2023-12-25T07:56:59.843Z</updated>
    
    <content type="html"><![CDATA[<h1 id="大数据原理期末复习"><a href="#大数据原理期末复习" class="headerlink" title="大数据原理期末复习"></a>大数据原理期末复习</h1><h2 id="Hadoop"><a href="#Hadoop" class="headerlink" title="Hadoop"></a>Hadoop</h2><h3 id="Hadoop的特点"><a href="#Hadoop的特点" class="headerlink" title="Hadoop的特点"></a>Hadoop的特点</h3><ol><li>扩容能力(Scalable)：<br>Hadoop是在计算机集群内分配并完成计算任务，集群可以方便的扩展到数以千个节点</li><li>低成本(Economical)：<br> Hadoop通过普通廉价的机器组成服务器集群来分发以及处理数据，以至于成本很低</li><li>高效率(Efficient)：<br>Hadoop可以在节点之间动态并行的移动数据，使得速度非常快</li><li>可靠性(Rellable)：<br>能自动维护数据的多份复制，并且在任务失败后能自动的重新部署计算任务</li></ol><p><img src="/../img/bigData/hadoop1.png" alt="Alt text"></p><h3 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h3><h3 id="HDFS读写流程"><a href="#HDFS读写流程" class="headerlink" title="HDFS读写流程"></a>HDFS读写流程</h3><h4 id="HDFS读-下载-流程"><a href="#HDFS读-下载-流程" class="headerlink" title="HDFS读(下载)流程"></a>HDFS读(下载)流程</h4><p><img src="/../img/bigData/hdfs_read.png" alt="hdfs_read"></p><ol><li>客户端通过Distributed FileSystem项<strong>NN</strong>请求下载文件，NN通过查询元数据，找到文件所在的DN(DataNode)地址</li><li>挑选一台DataNode(就近原则，然后随机)服务器，请求读取数据。</li><li>DN开始传输数据给客户端(从磁盘里面读取数据输入流，以Packet为单位来做校验)</li><li>客户端以Packet为单位接收，先在本地缓存，然后写入目标文件</li></ol><h4 id="HDFS写-上传-流程"><a href="#HDFS写-上传-流程" class="headerlink" title="HDFS写(上传)流程"></a>HDFS写(上传)流程</h4><p><img src="/../img/bigData/hdfs_write.png" alt="hdfs_write"></p><ol><li>客户端通过Distributed FileSystem模块向NN请求上传文件，NN检查目标文件是否已存在，父目录是否存在。</li><li>NN返回是否可以上传</li><li>客户端请求第一个Block上传到哪几个DataNode服务器上。</li><li>NN返回3个DataNode节点，分别为dn1、dn2、dn3</li><li>客户端通过FSDataOutputStream模块请求dn1上传数据，dn1收到请求会继续会调用dn2,然后dn2调用dn3,将这个通信管道建立完成。</li><li>dn1、dn2、dn3逐级应答客户端。</li><li>客户端开始往dn1上传第一个Block(先从磁盘读取数据放到一个本地内存缓存)，以Packet为单位，dn1收到一个Packet就会传给dn2,dn2传给dn3; dn1每传一个packet会放入一个确认队列等待确认。</li><li>当一个Block传输完成之后，客户端再次请求NN上传第二个Block的服务器。(重复执行3-7步)<br> 验证Packet代码 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"> <span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testUploadPacket</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line"><span class="comment">//1 准备读取本地文件的输入流</span></span><br><span class="line"><span class="keyword">final</span> <span class="type">FileInputStream</span> <span class="variable">in</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">FileInputStream</span>(<span class="keyword">new</span></span><br><span class="line"><span class="title class_">File</span>(<span class="string">&quot;e:/lagou.txt&quot;</span>));</span><br><span class="line"><span class="comment">//2 准备好写出数据到hdfs的输出流</span></span><br><span class="line"><span class="keyword">final</span> <span class="type">FSDataOutputStream</span> <span class="variable">out</span> <span class="operator">=</span> fs.create(<span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/lagou.txt&quot;</span>), <span class="keyword">new</span></span><br><span class="line"><span class="title class_">Progressable</span>() &#123;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">progress</span><span class="params">()</span> &#123; <span class="comment">//这个progress方法就是每传输64KB（packet）就会执行一次，</span></span><br><span class="line">System.out.println(<span class="string">&quot;&amp;&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line">&#125;);</span><br><span class="line"><span class="comment">//3 实现流拷贝</span></span><br><span class="line">IOUtils.copyBytes(in, out, configuration); <span class="comment">//默认关闭流选项是true，所以会自动关闭</span></span><br><span class="line"><span class="comment">//4 关流  可以再次关闭也可以不关了</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><h4 id="NN和SNN"><a href="#NN和SNN" class="headerlink" title="NN和SNN"></a>NN和SNN</h4><p>元数据管理流程图:<br><img src="/../img/bigData/snn_nn.png" alt="SNN和NN"></p><ol><li><p>NN(NameNode)</p><ul><li><p>NN是整个文件系统的管理节点（上传、下载、更改、删除）。它维护着整个文件系统的文件目录树，文件&#x2F;目录的元数据(meta data)和每个文件对应的数据块列表。接收用户的操作请求。</p></li><li><p>文件包括：</p><ul><li>fsimage: 元数据镜像文件。存储某一个时刻的NameNode内元数据信息</li><li>edits: 操作日志文件，NameNode启动后一些新增元信息日志。</li><li>fstime: 保存最近异常checkpoint的时间</li></ul></li><li><p>以上文件时保存在Linux的文件系统中。</p><ul><li>hdfs-site.xml的dfs.namenode.name.dir属性</li></ul></li></ul></li><li><p>SNN(Secondary NameNode)</p><ul><li>作用:<ul><li>辅助NN: SNN不是NN的热备份，而是辅助NN处理FSimage(文件系统的元数据)和Edits(记录了对文件系统所做更改的日志)。</li><li>合并edits和Fsimage: 定期合并fsimage和edits，减少NN重启时恢复文件系统状态的时间。合并过程称为<strong>Checkpoint</strong></li><li>减小NN的负担：通过定期创建Fsimage的检查点，SNN减轻了NN的内存和存储压力</li><li>灾难恢复：在NN发生故障时，SNN中的数据可以用于恢复文件系统的状态，虽然这不是它的主要目的。<br>  <strong>注意</strong>：SNN不是NN的热备份，他不能在NN故障时自动接管其职责。在hadoop2.x版本中，为了提供更高的可用性和灾难恢复能力，引入了HA(高可用性)架构，其中包括使用Active&#x2F;Standby两个NN</li></ul></li></ul></li><li><p>元数据管理流程图:<br><img src="/../img/bigData/snn_nn.png" alt="SNN和NN"><br>根据上图，可知NN和SNN的工作流程为：</p><ol><li>第一阶段：NN启动<ul><li>第一次启动NN格式化后，创建Fsimage和Edits文件。如果不是第一次启动，直接加载编辑日志和镜像文件到内存</li><li>客户端对元数据进行增删改的请求</li><li>NN记录操作日志，更新滚动日志</li><li>NN在内存中对数据进行增删查改</li></ul></li><li>第二阶段：SNN工作<ul><li>SNN询问NN是否需要CheckPoint。直接带回NN是否执行检查点操作结果</li><li>SNN请求执行CheckPoint</li><li>NN滚动正在写的Edits日志</li><li>将滚动前的编辑日志和镜像文件拷贝到SNN.</li><li>SNN加载编辑编辑日志和镜像文件到内存，并合并</li><li>生成新的镜像文件fsimage.checkpoint</li><li>拷贝fsimage.chkpoint到NN</li><li>NN 将fsimage.chkpoint重新命名为fsimage</li></ul></li></ol></li><li><p>CheckPoint</p><ol><li>fs.checkpoint.period指定两次CheckPoint的最大时间间隔默认为3600秒(1个小时)</li><li>fs.checkpoint.size规定edits文件的最大值，一旦超过这个值则强制checkpoint,不管是否到达最大时间间隔，默认是64M<br> [hdfs-default.xml]<pre><code class="xml">&lt;!-- 定时一小时 --&gt;    &lt;property&gt;    &lt;name&gt;dfs.namenode.checkpoint.period&lt;/name&gt;    &lt;value&gt;3600&lt;/value&gt;    &lt;/property&gt;    &lt;!-- 一分钟检查一次操作次数，当操作次数达到1百万时，SecondaryNameNode执行一次 --&gt;    &lt;property&gt;    &lt;name&gt;dfs.namenode.checkpoint.txns&lt;/name&gt;    &lt;value&gt;1000000&lt;/value&gt;    &lt;description&gt;操作动作次数&lt;/description&gt;    &lt;/property&gt;    &lt;property&gt;    &lt;name&gt;dfs.namenode.checkpoint.check.period&lt;/name&gt;    &lt;value&gt;60&lt;/value&gt;    &lt;description&gt; 1分钟检查一次操作次数&lt;/description&gt;    &lt;/property &gt;</code></pre></li></ol></li></ol><h2 id="HBase"><a href="#HBase" class="headerlink" title="HBase"></a>HBase</h2><h3 id="HBase读流程"><a href="#HBase读流程" class="headerlink" title="HBase读流程"></a>HBase读流程</h3><p>简略图1<br><img src="/../img/bigData/hbase_read.png" alt="Hbase_read"><br>图2<br><img src="/../img/bigData/hbase_read2.png" alt="Hbase_read2"></p><ol><li><p>首先从zk表找到meta表的region位置，然后读取meta表中的数据，meta表中存储了用户表的region信息</p></li><li><p>根据要查询的namespace、表名和rowkey信息。找到写入数据对应的region信息</p></li><li><p>找到这个region对应的regionServer,然后发送请求。</p></li><li><p>查找对应的region</p></li><li><p>先从metastore查找数据，如果没有，再从BlockCache上获取<br>HBase上RegionServer的内存分为两个部分</p><ul><li>一部分作为Memstore，主要用来写；</li><li>另外一部分作为BlockCache, 主要用于读数据；</li></ul></li><li><p>如果BlockCache中没有找到，再到StoreFile上进行读取。从StoreFile中读取到数据之后，不是直接把结果数据返回给客户端，而是把数据先写入到BlockCache中，目的是为了加快后续的查询；然后在返回结果给客户端。</p></li></ol><h3 id="HBase写流程"><a href="#HBase写流程" class="headerlink" title="HBase写流程"></a>HBase写流程</h3><p>简略图1<br><img src="/../img/bigData/hbase_write.png" alt="hbase_write"><br>图2<br><img src="/../img/bigData/hbase_write2.png" alt="hbase_write2"></p><ol><li>首先从zk找到meta表的region位置，然后读取meta表中的数据，meta中存储了用户表的region信息</li><li>根据namespace、表名和rowkey信息。找到写入数据库对应的region信息</li><li>找到这个region对应的regionServer，然后发送请求</li><li>把数据分别写到HLog(write ahead log) 和metastore各一份</li><li>memstore达到阈值后把数据刷到磁盘，生成storeFile文件</li><li>删除HLog中的历史数据</li></ol><h2 id="资源调度YARN"><a href="#资源调度YARN" class="headerlink" title="资源调度YARN"></a>资源调度YARN</h2><p>Apache Hadoop YARN是 Hadoop的子项目，为分离Hadoop2.0资源管理和计算组件而引入，是一个资源调度平台，负责为运算程序提供服务器运算资源，相当于一个分布式的操作系统平台，而MapReduce等运算程序则相当于运行于操作系统之上的应用程序。<br>关于 YARN,有几点需要明白的是：</p><ol><li>实际上，YARN并不清楚用户所提交程序的运行机制是什么；</li><li>YARN只负责提供运算资源的调度(用户程序向YARN申请资源，YARN就负责分配资源)</li><li>YARN中的主管角色是<strong>ResourceManager</strong>，而具体提供运算资源的角色是<strong>NodeManager</strong></li><li>YARN框架与运行的用户程序完全解耦，这就意味着在YARN上面可以运行各种类型的分布式运算程序(MR只是其中的一种)，如strom程序、spark程序……</li><li>YARN就是一个通用的资源调度平台，企业中以前存在的各种运算集群都可以整合在一个物理集群上，提高资源利用率，方便数据共享。</li></ol><h3 id="YARN架构"><a href="#YARN架构" class="headerlink" title="YARN架构"></a>YARN架构</h3><p><img src="/../img/bigData/yarn_arch1.png" alt="YARN_acrh"><br><img src="/../img/bigData/yarn_arch2.png" alt="yarn_arch1"></p><ol><li>ResourceManager(RM)：处理客户端请求、启动&#x2F;监控ApplicationMaster、监控NodeManager、资源分配与调度</li><li>NodeManager(NM)：单个节点上的资源管理、处理来自ResourceManager的命令、处理来自ApplicationMaster的命令</li><li>ApplicationMaster(am)：数据切分、为应用程序申请资源、并分配给内部任务、任务监控与容错。</li><li>Conatiner：对任务运行环境的抽象、封装了CPU、内存等多维资源以及环境变量、启动命令等任务运行相关的信息</li></ol><h3 id="YARN工作机制"><a href="#YARN工作机制" class="headerlink" title="YARN工作机制"></a>YARN工作机制</h3><p><img src="/../img/bigData/yarn_work.png" alt="yarn_work"></p><ul><li>作业提交<ol><li>Client调用job.waitForCompletion方法，向整个集群提交MR作业</li><li>Client向RM申请一个作业id</li><li>RM给Client返回该job资源的提交路径和作业id</li><li>Client提供jar包，切片信息和配置文件到指定的资源提交路径</li><li>Client提交完资源后，向RM申请运行MrAppMaster</li></ol></li><li>作业初始化<ol start="6"><li>当RM收到Client的请求后，将该job添加到容量调度器中。</li><li>某一个空闲的NM领取到Job</li><li>该NM创建Container,并产生MRAppMaster</li><li>下载Client提交的资源到本地</li></ol></li><li>任务分配<ol start="10"><li>MRAppMaster向RM申请运行多个MapTask任务资源</li><li>RM将运行MapTask任务分配给另外两个NodeManager,另外两个NodeManager分别领取任务并创建容器</li></ol></li><li>任务运行<ol start="12"><li>MR向两个接收到任务的NodeManager发送程序启动脚本，这两个NodeManager分别启动MapTask.MapTask对数据分区排序</li><li>MrAppMaster等待所有MapTask运行完毕后，向RM申请容器，运行ReduceTask.</li><li>ReduceTask向MapTask获取相应分区的数据</li><li>程序运行完毕后，MR会向RM申请注销自己</li></ol></li><li>进度和状态更新<br>  YARN中的任务将其进度和状态返回给应用管理器，客户端每秒(通过mapreduce.client.progressmonitor.pollinterval设置)向应用管理器请求进度更新，展示给用户</li><li>作业完成<br>  除了向应用管理器请求作业进度外，客户端每5秒都会通过调用waitForCompletion()来检查作业是否完成。时间间隔可以通过mapreduce.client.completion.pollinterval来设置。作业完成之后，应用管理器和Container会清理工作状态。作业的信息会被作业历史服务器存储以备之后用户核查</li></ul><h3 id="YARN生命周期"><a href="#YARN生命周期" class="headerlink" title="YARN生命周期"></a>YARN生命周期</h3><p><img src="/../img/bigData/yarn_lifetime.png" alt="yarn_lifetime"></p><h2 id="Zookeeper"><a href="#Zookeeper" class="headerlink" title="Zookeeper"></a>Zookeeper</h2><h3 id="Zookeeper是什么？"><a href="#Zookeeper是什么？" class="headerlink" title="Zookeeper是什么？"></a>Zookeeper是什么？</h3><p>Zookeeper是一个分布式协调服务的开源框架。主要用来解决<strong>分布式集群中应用系统的一致性问题</strong>，例如怎样避免同时操作同一数据造成脏读的问题。分布式系统中数据存在一致性的问题！！  </p><ul><li><strong>ZooKeeper本质上是一个分布式的小文件存储系统</strong>。提供基于类似于文件系统的目录树方式的数据存储，并且可以对树中的节点进行有效管理。</li><li><strong>Zookeeper提供给客户端监控存储在zk内部数据的功能</strong>，从而可以达到基于数据的集群管理。诸如：统⼀命名服务(dubbo)、分布式配置管理(solr的配置集中管理)、分布式消息队列<br>（sub&#x2F;pub）、分布式锁、分布式协调等功能。</li></ul><h3 id="Zookeeper的架构组成"><a href="#Zookeeper的架构组成" class="headerlink" title="Zookeeper的架构组成"></a>Zookeeper的架构组成</h3><p><img src="/../img/bigData/zookper1.png" alt="zookeeper"></p><ol><li><strong>Leader</strong>:  <ul><li>Zookeeper 集群⼯作的核⼼⻆⾊</li><li>集群内部各个服务器的调度者。</li><li>事务请求（写操作） 的<strong>唯⼀调度和处理者</strong>，保证集群事务处理的顺序性；对于 create，<br>setData， delete 等有写操作的请求，则需要统⼀转发给leader 处理， leader 需要决定编号、执⾏操作，这个过程称为⼀个事务。</li></ul></li><li><strong>Follower</strong>:<ul><li>处理客户端⾮事务（读操作） 请求，</li><li>转发事务请求给 Leader；</li><li>参与集群 Leader 选举投票 2n-1台可以做集群投票。</li></ul></li></ol><p>此外，针对访问量⽐较⼤的 zookeeper 集群， 还可新增观察者⻆⾊。  </p><ol start="3"><li><strong>Observer</strong>:<ul><li>观察者⻆⾊，观察 Zookeeper 集群的最新状态变化并将这些状态同步过来，其对于⾮事务请求可以进行独⽴处理，对于事务请求，则会转发给 Leader服务器进⾏处理。</li><li>不会参与任何形式的投票只提供⾮事务服务，通常⽤于在不影响集群事务处理能⼒的前提下提升集群的⾮事务处理能⼒。增加了集群增加并发的读请求。</li></ul></li></ol><p><img src="/../img/bigData/zookper2.png" alt="zookper2"></p><h3 id="Zookeeper的工作特点"><a href="#Zookeeper的工作特点" class="headerlink" title="Zookeeper的工作特点"></a>Zookeeper的工作特点</h3><ol><li>Zookeeper：⼀个领导者（leader:⽼⼤），多个跟随者（follower:⼩弟）组成的集群。</li><li>Leader负责进⾏投票的发起和决议，更新系统状态(内部原理)</li><li>Follower⽤于接收客户请求并向客户端返回结果，在选举Leader过程中参与投票</li><li>集群中只要有半数以上节点存活，Zookeeper集群就能正常服务。</li><li>全局数据⼀致：每个server保存⼀份相同的数据副本，Client⽆论连接到哪个server，数据都是⼀<br>致的。</li><li>更新请求顺序进⾏(内部原理)</li><li>数据更新原⼦性，⼀次数据更新要么成功，要么失败。</li></ol><h3 id="Zookeeper数据结构与监听机制"><a href="#Zookeeper数据结构与监听机制" class="headerlink" title="Zookeeper数据结构与监听机制"></a>Zookeeper数据结构与监听机制</h3><p><strong>ZooKeeper数据模型Znode</strong>：<br>在ZooKeeper中，数据信息被保存在⼀个个数据节点上，这些节点被称为znode。ZNode 是<br>Zookeeper 中最⼩数据单位，在 ZNode 下⾯⼜可以再挂 ZNode，这样⼀层层下去就形成了⼀个层次化<br>命名空间 ZNode 树，我们称为 ZNode Tree，它采⽤了类似⽂件系统的层级树状结构进⾏管理。⻅下图<br>示例：<br><img src="/../img/bigData/zookeeper_znode1.png" alt="zookeeper_znode1"></p><p>在 Zookeeper 中，每⼀个数据节点都是⼀个 ZNode，上图根⽬录下有两个节点，分别是：app1 和<br>app2，其中 app1 下⾯⼜有三个⼦节点,所有ZNode按层次化进⾏组织，形成这么⼀颗树，ZNode的节<br>点路径标识⽅式和Unix⽂件系统路径⾮常相似，都是由⼀系列使⽤斜杠（&#x2F;）进⾏分割的路径表示，开<br>发⼈员可以向这个节点写⼊数据，也可以在这个节点下⾯创建⼦节点。</p><h4 id="ZNode的类型"><a href="#ZNode的类型" class="headerlink" title="ZNode的类型"></a>ZNode的类型</h4><p>Zookeeper 节点类型可以分为三⼤类：</p><ul><li>持久性节点（Persistent）</li><li>临时性节点（Ephemeral）</li><li>顺序性节点（Sequential）</li></ul><p>在开发中在创建节点的时候通过组合可以⽣成以下四种节点类型：<strong>持久节点、持久顺序节点、临时节<br>点、临时顺序节点</strong>。不同类型的节点则会有不同的⽣命周期：</p><ul><li>持久节点：是Zookeeper中最常⻅的⼀种节点类型，所谓持久节点，就是指节点被创建后会⼀直存在服<br>务器，直到删除操作主动清除</li><li>持久顺序节点：就是有顺序的持久节点，节点特性和持久节点是⼀样的，只是额外特性表现在顺序上。<br>顺序特性实质是在创建节点的时候，会在节点名后⾯加上⼀个数字后缀，来表示其顺序。</li><li>临时节点：就是会被⾃动清理掉的节点，它的⽣命周期和客户端会话绑在⼀起，客户端会话结束，节点<br>会被删除掉。与持久性节点不同的是，临时节点不能创建⼦节点。</li><li>临时顺序节点：就是有顺序的临时节点，和持久顺序节点相同，在其创建的时候会在名字后⾯加上数字后缀。</li><li><strong>事务ID</strong><br>⾸先，先了解，事务是对物理和抽象的应⽤状态上的操作集合。往往在现在的概念中，ሀ义上的事务通<br>常指的是数据库事务，⼀般包含了⼀系列对数据库有序的读写操作，这些数据库事务具有所谓的ACID特<br>性，即原⼦性（Atomic）、⼀致性（Consistency）、隔离性（Isolation）和持久性（Durability）。<br>⽽在ZooKeeper中，事务是指能够改变ZooKeeper服务器状态的操作，我们也称之为事务操作或更新<br>操作，⼀般包括数据节点创建与删除、数据节点内容更新等操作。对于每⼀个事务请求，ZooKeeper都<br>会为其分配⼀个全局唯⼀的事务ID，⽤ ZXID 来表示，通常是⼀个 64 位的数字。每⼀个 ZXID 对应⼀次<br>更新操作，从这些ZXID中可以间接地识别出ZooKeeper处理这些更新操作请求的全局顺序。<br>zk中的事务指的是对zk服务器状态改变的操作(create,update data,更新字节点)；zk对这些事务操作都<br>会编号，这个编号是⾃增⻓的被称为ZXID。</li></ul><h4 id="Watcher机制-观察者模式"><a href="#Watcher机制-观察者模式" class="headerlink" title="Watcher机制 (观察者模式)"></a>Watcher机制 (观察者模式)</h4><p>Zookeeper使⽤Watcher机制实现分布式数据的发布&#x2F;订阅功能，⼀个典型的发布&#x2F;订阅模型系统定义了⼀种、⼀对多的订阅关系，能够让多个订阅者同时监听某⼀个主题<br>对象，当这个主题对象⾃身状态变化时，会通知所有订阅者，使它们能够做出相应的处理。<br>在 ZooKeeper 中，引⼊了 Watcher 机制来实现这种分布式的通知功能。<strong>ZooKeeper 允许客户端向服务端注册⼀个 Watcher 监听</strong>，当服务端的⼀些指定事件触发了这个 Watcher，那么Zk就会向指定客户端<br>发送⼀个事件通知来实现分布式的通知功能。</p><p>整个Watcher注册与通知过程如图所示。<br><img src="/../img/bigData/zookeeper_watcher.png" alt="zookeeper_watcher">  </p><p>Zookeeper的Watcher机制主要包括<strong>客户端线程、客户端WatcherManager、Zookeeper服务器</strong>三部<br>分。<br>具体⼯作流程为：</p><ul><li>客户端在向Zookeeper服务器注册的同时，会将Watcher对象存储在客户端的WatcherManager当<br>中</li><li>当Zookeeper服务器触发Watcher事件后，会向客户端发送通知</li><li>客户端线程从WatcherManager中取出对应的Watcher对象来执⾏回调逻辑</li></ul><h3 id="Zookeeper内部原理"><a href="#Zookeeper内部原理" class="headerlink" title="Zookeeper内部原理"></a>Zookeeper内部原理</h3><h4 id="Leader选举"><a href="#Leader选举" class="headerlink" title="Leader选举"></a>Leader选举</h4><ol><li><p>选举机制</p><ul><li>半数机制：集群中半数以上机器存活，集群可⽤。所以Zookeeper适合安装奇数台服务器。</li><li>Zookeeper虽然在配置⽂件中并没有指定Master和Slave。但是，Zookeeper⼯作时，是有⼀个节点为Leader，其它为Follower，Leader是通过内部的选举机制产⽣的。</li></ul></li><li><p>集群⾸次启动<br>假设有五台服务器组成的Zookeeper集群，它们的id从1-5，同时它们都是最新启动的，也就是没有历史<br>数据，在存放数据量这⼀点上，都是⼀样的。假设这些服务器依序启动，来看看会发⽣什么，<br><img src="/../img/bigData/hadoop1.png" alt="zookeeper_leader"><br>Zookeeper的选举机制<br>（1）服务器1启动，此时只有它⼀台服务器启动了，它发出去的报⽂没有任何响应，所以它的选举状态<br>⼀直是LOOKING状态。<br>（2）服务器2启动，它与最开始启动的服务器1进⾏通信，互相交换⾃⼰的选举结果，由于两者都没有<br>历史数据，所以id值较⼤的服务器2胜出，但是由于没有达到超过半数以上的服务器都同意选举它(这个<br>例⼦中的半数以上是3)，所以服务器1、2还是继续保持LOOKING状态。<br>（3）服务器3启动，根据前⾯的理论分析，服务器3成为服务器1、2、3中的⽼⼤，⽽与上⾯不同的<br>是，此时有三台服务器选举了它，所以它成为了这次选举的Leader。<br>（4）服务器4启动，根据前⾯的分析，理论上服务器4应该是服务器1、2、3、4中最⼤的，但是由于前<br>⾯已经有半数以上的服务器选举了服务器3，所以它只能接收当⼩弟的命了。<br>（5）服务器5启动，同4⼀样称为follower。</p></li><li><p>集群⾮⾸次启动<br>每个节点在选举时都会参考⾃身节点的zxid值（事务ID）；优先选择zxid值⼤的节点称为Leader!!</p></li></ol><h4 id="ZAB⼀致性协议"><a href="#ZAB⼀致性协议" class="headerlink" title="ZAB⼀致性协议"></a>ZAB⼀致性协议</h4><p>ZK就是分布式⼀致性问题的⼯业解决⽅案，paxos是其底层理论算法(晦涩难懂著名)，其中zab，raft和<br>众多开源算法是对paxos的⼯业级实现。ZK没有完全采⽤paxos算法，⽽是使⽤了⼀种称为Zookeeper<br>Atomic Broadcast（ZAB，Zookeeper原⼦消息⼴播协议）的协议作为其数据⼀致性的核⼼算法。<br><strong>ZAB协议</strong><br>ZAB 协议是为分布式协调服务 Zookeeper 专⻔设计的⼀种⽀持崩溃恢复和原⼦⼴播协议。<br><strong>主备模式保证⼀致性</strong><br><img src="/../img/bigData/zab.png" alt="ZAB"><br>ZK怎么处理集群中的数据？所有客户端写⼊数据都是写⼊Leader中，然后，由 Leader 复制到Follower<br>中。ZAB会将服务器数据的状态变更以事务Proposal的形式⼴播到所有的副本进程上，ZAB协议能够保<br>证了事务操作的⼀个全局的变更序号(ZXID)。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;大数据原理期末复习&quot;&gt;&lt;a href=&quot;#大数据原理期末复习&quot; class=&quot;headerlink&quot; title=&quot;大数据原理期末复习&quot;&gt;&lt;/a&gt;大数据原理期末复习&lt;/h1&gt;&lt;h2 id=&quot;Hadoop&quot;&gt;&lt;a href=&quot;#Hadoop&quot; class=&quot;head</summary>
      
    
    
    
    <category term="学习总结" scheme="https://gyhpcg.gihthub.io/categories/%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    
    
    <category term="big data" scheme="https://gyhpcg.gihthub.io/tags/big-data/"/>
    
  </entry>
  
  <entry>
    <title>设计模式</title>
    <link href="https://gyhpcg.gihthub.io/2023/11/23/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    <id>https://gyhpcg.gihthub.io/2023/11/23/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/</id>
    <published>2023-11-23T10:22:05.000Z</published>
    <updated>2024-01-01T05:22:05.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="设计模式"><a href="#设计模式" class="headerlink" title="设计模式"></a>设计模式</h1><h2 id="一-设计模式六大原则"><a href="#一-设计模式六大原则" class="headerlink" title="一. 设计模式六大原则"></a>一. 设计模式六大原则</h2><p>总原则–开闭原则</p><blockquote><p>一个软件实体一个对扩展开放，对修改关闭</p></blockquote><ol><li>单一职责原则<blockquote><p>一个类应该只有一个引起发生变化的原因</p></blockquote></li><li>里氏替换原则<blockquote><p>所有使用父类的地方都可以用子类对象来替换（子类对父类的方法尽量不要重写和重载）</p></blockquote></li><li>依赖倒转原则<blockquote><ol><li>上层模块不应该依赖底层模块，它们都应该依赖抽象</li><li>抽象不应该依赖于细节，细节应该依赖于抽象</li></ol></blockquote></li><li>接口隔离原则<blockquote><ol><li>客户端不应该依赖它不需要的接口</li><li>类间的依赖关系应该建立在最小的接口上</li></ol></blockquote></li><li>迪米特原则（最小知道原则）<blockquote><p>只与你的直接朋友交谈，不跟“陌生人”说话<br>一个类对自己依赖的类知道的越少越好。无论被依赖的类多么复杂，都应该将逻辑封装在方法的内部，通过public 方法提供给外部</p></blockquote></li><li>合成复用原则（组合优先于继承）<blockquote><p>尽量使用对象组合&#x2F;聚合，而不是继承关系达到软件复用的目的 </p></blockquote></li><li>设计模式的优点和好处是什么？<ol><li>重用设计，重用设计比重用代码更有意义，它会自动带来代码的重用。</li><li>为设计提供共同的词汇，每个模式名就是一个设计词汇，其概念诗程序员间的交流更方便。</li><li>在开发文档中采用模式词汇可以让其他人更容易理解你的想法和做法，编写开发文档也更方便。</li><li>应用设计模式可以让重构系统变得容易，可以确保开发正确的代码，并降低在设计或实现中出现的错误的可能。</li><li>支持变化，可以为重写其他应用程序提供很好的系统架构。</li><li>正确设计模式，可以节省大量时间。</li></ol></li><li>MVC是什么？<br>M: 模型 V:视图 C:控制器</li></ol><h2 id="二-设计模式的三大类"><a href="#二-设计模式的三大类" class="headerlink" title="二. 设计模式的三大类"></a>二. 设计模式的三大类</h2><ol><li>创建型模式：对类的实例化过程进行了抽象，能够将软件模块中对象的创建和对象的使用分离。工厂模式、抽象工厂模式、单例模式、建造者模式、原型模式</li><li>结构型模式：关注于对象的组成以及对象之间的依赖关系，描述如何将类或者对象结合在一起形成更大的结构，就像搭积木，可以通过简单积木的组合形成复杂的、功能更为强大的结构。 适配器模式、装饰者模式、代理模式、外观模式、桥接模式、组合模式、享元模式。</li><li>行为型模式：关注于对象的行为问题，是对在不同的对象之间划分责任和算法的抽象化；不仅仅关注类和对象的结构，而且重点关注它们之间的相互作用。<blockquote><p>策略模式、模板方法模式、观察者模式、迭代器模式、责任链模式、命令模式、备忘录模式、状态模式、访问者模式、中介者模式、解释器模式</p></blockquote></li></ol><h2 id="三-23种设计模式"><a href="#三-23种设计模式" class="headerlink" title="三. 23种设计模式"></a>三. 23种设计模式</h2><ol><li><p><strong>原型模式</strong>：<br>通过复制现有的实例和对象来创建新的实例，而不需要知道相应类的细节。<br>简单地理解，其实就是当需要创建一个指定的对象时，我们刚好有一个这样的对象，但是又不能直接使用，我会clone一个一毛一样的新对象来使用；基本上这就是原型模式。关键字：Clone。<br>类图如下：<br><img src="/../img/designPattern/prototype.png" alt="prototype"></p></li><li><p><strong>外观模式</strong>：<br>隐藏了系统的复杂性，并向客户端提供了一个可以访问系统的接口。</p></li><li><p><strong>适配器模式</strong>：<br>适配器模式将某个类的接口转换成客户端期望的另一个接口表示，目的是消除由于接口不匹配所造成的类的兼容性问题。<br><strong>分类</strong>：类的适配器模式、对象的适配器模式、接口的适配器模式。</p></li><li><p><strong>建造者模式</strong>：封装一个复杂对象构造过程，并允许按步骤构造。</p></li><li><p><strong>备忘录模式</strong>：<br>定义： 在不破坏封装性的前提下，捕获一个对象的内部状态，并在该对象之外保存这个状态，以便以后当需要时能将该对象恢复到原先保存的状态。该模式又叫<strong>快照模式</strong>。<br>备忘录模式是一种对象行为型模式，其主要优点如下。</p><ul><li>提供了一种可以恢复状态的机制。当用户需要时能够比较方便地将数据恢复到某个历史的状态。  </li><li>实现了内部状态的封装。除了创建它的发起人之外，其他对象都不能够访问这些状态信息。   </li><li>简化了发起人类。发起人不需要管理和保存其内部状态的各个备份，所有状态信息都保存在备忘录中，并由管理者进行管理，这符合单一职责原则。<br>其主要缺点是：资源消耗大。如果要保存的内部状态信息过多或者特别频繁，将会占用比较大的内存资源。</li></ul></li><li><p><strong>命令模式</strong>：<br>定义：将一个请求封装为一个对象，使发出请求的责任和执行请求的责任分割开。这样两者之间通过命令对象进行沟通，这样方便将命令对象进行储存、传递、调用、增加与管理。<br>意图：将一个请求封装成一个对象，从而使您可以用不同的请求对客户进行参数化。<br>主要解决：在软件系统中，行为请求者与行为实现者通常是一种紧耦合的关系，但某些场合，比如需要对行为进行记录、撤销或重做、事务等处理时，这种无法抵御变化的紧耦合的设计就不太合适。<br>何时使用：在某些场合，比如要对行为进行”记录、撤销&#x2F;重做、事务”等处理，这种无法抵御变化的紧耦合是不合适的。在这种情况下，如何将”行为请求者”与”行为实现者”解耦？将一组行为抽象为对象，可以实现二者之间的松耦合。<br>如何解决：通过调用者调用接受者执行命令，顺序：调用者→接受者→命令。</p></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;设计模式&quot;&gt;&lt;a href=&quot;#设计模式&quot; class=&quot;headerlink&quot; title=&quot;设计模式&quot;&gt;&lt;/a&gt;设计模式&lt;/h1&gt;&lt;h2 id=&quot;一-设计模式六大原则&quot;&gt;&lt;a href=&quot;#一-设计模式六大原则&quot; class=&quot;headerlink&quot; titl</summary>
      
    
    
    
    <category term="学习总结" scheme="https://gyhpcg.gihthub.io/categories/%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    
    
    <category term="设计模式" scheme="https://gyhpcg.gihthub.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>hexo搭建测试</title>
    <link href="https://gyhpcg.gihthub.io/2023/11/06/hexo%E6%90%AD%E5%BB%BA%E6%B5%8B%E8%AF%95/"/>
    <id>https://gyhpcg.gihthub.io/2023/11/06/hexo%E6%90%AD%E5%BB%BA%E6%B5%8B%E8%AF%95/</id>
    <published>2023-11-06T04:57:10.000Z</published>
    <updated>2023-11-06T05:23:35.482Z</updated>
    
    <content type="html"><![CDATA[<h1 id="first-test"><a href="#first-test" class="headerlink" title="first test"></a>first test</h1><h1 id="second-test"><a href="#second-test" class="headerlink" title="second test"></a>second test</h1><h2 id="hello-test"><a href="#hello-test" class="headerlink" title="hello test"></a>hello test</h2>]]></content>
    
    
    <summary type="html">关于hexo搭建的一些测试</summary>
    
    
    
    
    <category term="environment" scheme="https://gyhpcg.gihthub.io/tags/environment/"/>
    
  </entry>
  
  <entry>
    <title>2023rcore第二阶段学习总结</title>
    <link href="https://gyhpcg.gihthub.io/2023/11/05/rcore_study/"/>
    <id>https://gyhpcg.gihthub.io/2023/11/05/rcore_study/</id>
    <published>2023-11-05T15:09:21.000Z</published>
    <updated>2023-11-06T13:12:55.447Z</updated>
    
    <content type="html"><![CDATA[<h1 id="2023rcore第二阶段学习总结和个人与计算机系统的漫游"><a href="#2023rcore第二阶段学习总结和个人与计算机系统的漫游" class="headerlink" title="2023rcore第二阶段学习总结和个人与计算机系统的漫游"></a>2023rcore第二阶段学习总结和个人与计算机系统的漫游</h1><h2 id="初识"><a href="#初识" class="headerlink" title="初识"></a>初识</h2><p>与 <a href="https://github.com/LearningOS">rcore开源操作系统训练营</a> 的相识，算是一个很偶然的机会吧。我与计算机结识很晚，在我上大学后，才从一个对计算机连打字都不会的人到慢慢熟练使用以及熟悉各种技术的人。与操作系统(Linux)结识，是大一下学期的 计算机系统基础课(教程是那本鼎鼎大名的 <strong>深入了解计算机系统</strong>)，那节课开启了我Linux的漫游旅途。</p><h2 id="兴趣"><a href="#兴趣" class="headerlink" title="兴趣"></a>兴趣</h2><p>在我刚接触计算机的时候，一直认为开发出一个web网站或者APP，就是一件特别特别酷的事情。在整个刚接触计算机的事情，写出一个web网页或者APP便是我一直想要做的事。但后来，大一结束的暑假，学习了一些这方面的技术，扒开了web的真实面目，便慢慢失去了很多兴趣，曾经很酷的事情，突然感觉很无味了。所幸的是，在这个时候，学校的 <strong>OS</strong> 课开了，杨老师是一名非常知识渊博、热爱体系结构的老师，他 <strong>OS</strong> 第一门课留给我们的作业便是</p><blockquote><p>下载linux内核源码，并往内核中添加自定义系统调用</p></blockquote><p>这算是我开启了我正式与操作系统内核接触的旅途。永远无法忘却第一次下载linux内核源码，然后编译的时候，满屏报错的电脑界面，特别是每次编译的时候，都会让我等待很久，几乎每次都是编译了三十多分钟，然后给我报错，如此循环往复……最后终于把代码编译完成。第一次进入<strong>kernel</strong> 目录下，进入代码里面，映入眼帘的是 <strong>Linus Torvalds</strong> 的大名，那是我第二次那么激动(第一次激动的时候是第一次敲出 “Hello, World”)。最后在各种操作之下，各种文件之间来回修改的条件下，我终于让自己自定义的一个系统调用成功运行了起来，那一瞬间，像是打开了潘多拉的魔盒，从此我开始对体系结构、操作系统方向的东西产生了很大兴趣，便也萌生了写一个OS的想法，从此整个想法，便一直根深蒂固着。</p><h2 id="遇见rcore"><a href="#遇见rcore" class="headerlink" title="遇见rcore"></a>遇见rcore</h2><p>诚恳的说，我是因为心中那个根深蒂固的想法才会有机会遇见rcore，刚开始的时候，我其实知道的是 <strong>ucore</strong>, 后来因为个人非常喜欢c++，而某段的时间里，网上的各样信息都在告诉我 <strong>Rust</strong> 是c++的强大竞争者，<strong>Rust</strong> 是如何的安全，如何的高效。便萌发了我对这一门新型语言的兴趣。</p><h3 id="Rust"><a href="#Rust" class="headerlink" title="Rust:"></a>Rust:</h3><p>第一次用Rust的时候，它的cargo便惊艳了我很久，用c++的时候，每次安装第三方包，亦或是换个平台，编译东西，都会让我折磨很久，总是在各种编译器之间的实现困惑，msvc有的特性，在gcc有时候却无法运行，有时候在gcc能够运行的东西，在clang也无法运行。同样让人痛苦的时候，c++20&#x2F;c++23都出了很久了，但是不同编译器的支持却是层出不穷……。换到Rust，突然很多东西便让人清爽了许多。也便逐渐开始了学习Rust的旅途。</p><h3 id="risc-v"><a href="#risc-v" class="headerlink" title="risc-v:"></a>risc-v:</h3><p>对于risc-v的了解，在开始rcore之前，我也只知道它是开源的，文档内容少(远没有X86和Arm那样内容复杂和繁冗)。后来了解了一下龙芯，<a href="https://oscpu.github.io/ysyx/">一生一芯</a>等，便也对risc-v有了极大兴趣，恰逢此时，rcore便出现在了我面前。</p><h3 id="rcore"><a href="#rcore" class="headerlink" title="rcore:"></a>rcore:</h3><p><a href="https://rcore-os.cn/rCore-Tutorial-Book-v3/index.html">rcore Book</a> 的娓娓道来，特别是以各种史前生物 来描述，增加了一番故事书的趣味。而<a href="http://learningos.cn/rCore-Tutorial-Guide-2023A/">Guide</a>则能够快速地让我明白了代码地框架，每个文件，每个模块是什么样的功能。但无奈个人基础不好，所以大部分时间还是在看 Book。本次实验让我们实现操作系统核心的几个重要功能：</p><ol><li>多到程序与分时多道任务</li></ol><ul><li>Lab1 需要完善系统调用。对于 sys_task_info 系统调用，我们在 TCP 添加相应字段处理即<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">sys_task_info</span>(ti: *<span class="keyword">mut</span> TaskInfo) <span class="punctuation">-&gt;</span> <span class="type">isize</span> &#123;</span><br><span class="line">        <span class="keyword">unsafe</span>&#123;</span><br><span class="line">        *ti = TaskInfo&#123;</span><br><span class="line">            status:<span class="title function_ invoke__">get_current_status</span>(),</span><br><span class="line">            syscall_times:<span class="title function_ invoke__">get_syscall_times</span>(),</span><br><span class="line">            time : (<span class="title function_ invoke__">get_time_us</span>() - <span class="title function_ invoke__">get_current_start_time</span>()) / <span class="number">1000</span></span><br><span class="line"></span><br><span class="line">        &#125;;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="number">0</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><ol start="2"><li><p>虚拟内存管理  </p><p> 这部分的内容中，为 Rcore 引入了虚拟内存，为地址空间加上了一层抽象，# 地址空间<br> 刚学计算机的时候，个人非常总喜欢将所有代码放在一个文件里，觉得分开各种代码很是麻烦。后来因为学习深入，开始对分离代码，抽象多了很多体会。特别是在学计算机网络的TCP&#x2F;IP模型和操作系统的时候，对<strong>抽象，加层</strong>的思想确实是不断体会，不断明白了那句话“在计算机中，没有什么是不能加一层解决不了的”。现在来好好感受在ch4中的抽象加一层。</p><ol><li><p>为什么要添加一层抽象层：</p><ul><li>从应用开发的角度看，需要应用程序决定自己会被加载到哪个物理地址运行，需要直接访问真实的物理内存。这就要求应用开发者对于硬件的特性和使用方法有更多了解，产生额外的学习成本，也会为应用的开发和调试带来不便</li><li>从内核的角度来看，将直接访问物理内存的权力下放到应用会使得它难以对应用程序的访存行为进行有效管理，已有的特权级机制亦无法阻止很多来自应用程序的恶意行为。</li></ul></li><li><p>该抽象层要完成的目标：</p><ul><li><p>透明 ：应用开发者可以不必了解底层真实物理内存的硬件细节，且在非必要时也不必关心内核的实现策略， 最小化他们的心智负担；</p></li><li><p>高效 ：这层抽象至少在大多数情况下不应带来过大的额外开销；</p></li><li><p>安全 ：这层抽象应该有效检测并阻止应用读写其他应用或内核的代码、数据等一系列恶意行为。</p></li></ul></li></ol></li><li><p>进程管理</p><ul><li>对于进程、程序、可执行文件等的了解更加深入了<ol><li>进程是在操作系统管理下的程序的一次执行过程，程序是一个静态的概念。</li><li>可执行文件是一张“蓝图”：一张编译器解析源代码之后总结出的一张记载如何利用各种硬件资源进行一轮生产流程的 <strong>蓝图</strong></li><li>加载同一个可执行文件的两个进程也是不同的：它们的启动时间、占据的硬件资源、输入数据均有可能是不同的，这些条件均会导致它们是不一样的执行过程。</li><li>对于创建进程需要fork()和exec()两个系统调用而不只是一个系统调用。两个组合更加灵活，fork是为了 exec 一个新应用提供空间，然后exec可以读取不同的elf文件，执行不同的操作。</li></ol></li></ul></li><li><p>文件系统(未完待续)</p></li><li><p>并发(未完待续)</p></li></ol><p>但很可惜，因为个人基础和时间还有其他各种各样的原因，个人并没有完成五个实验，前面三个实验也只是勉强完成（虽然运行过了，但还是有很多东西之间还不明白）。接下来的时间，我将好好把先前没有弄明白的知识点再好好梳理一遍。并将继续做完还没有先前没有做完的工作。向训练营各位优秀的同学学习，以后要多写博客，多写博客(这次学到的一个优秀习惯)，及时梳理知识。纸上得来终觉浅，绝知此事要躬行！！！。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;2023rcore第二阶段学习总结和个人与计算机系统的漫游&quot;&gt;&lt;a href=&quot;#2023rcore第二阶段学习总结和个人与计算机系统的漫游&quot; class=&quot;headerlink&quot; title=&quot;2023rcore第二阶段学习总结和个人与计算机系统的漫游&quot;&gt;&lt;/a</summary>
      
    
    
    
    <category term="学习总结" scheme="https://gyhpcg.gihthub.io/categories/%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    
    
    <category term="Rust" scheme="https://gyhpcg.gihthub.io/tags/Rust/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="https://gyhpcg.gihthub.io/2023/11/05/hello-world/"/>
    <id>https://gyhpcg.gihthub.io/2023/11/05/hello-world/</id>
    <published>2023-11-05T14:28:16.264Z</published>
    <updated>2023-11-06T03:22:56.979Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.io/docs/&quot;&gt;documentation&lt;/a&gt; for</summary>
      
    
    
    
    
  </entry>
  
</feed>
